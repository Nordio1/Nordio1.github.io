{
  "pt": {
    "meta": {
      "title": "Johnny Nordio | Engenheiro de IA",
      "description": "Engenheiro de Inteligência Artificial focado em IA Generativa, LLMs, RAG, agentes e LLMOps.",
      "ogDescription": "IA Generativa • LLMs • RAG • Agentes • LLMOps"
    },
    "profile": {
      "email": "mrnordio@icloud.com",
      "whatsapp": "https://wa.me/5541995879232",
      "github": "https://github.com/Nordio1",
      "linkedin": "https://br.linkedin.com/in/johnny-nordio-533769251"
    },
    "nav": {
      "about": "Resumo",
      "skills": "Competências",
      "projects": "Projetos",
      "experience": "Experiência",
      "education": "Formação",
      "contact": "Contato",
      "lab": "Arquiteturas",
      "toolbox": "Toolbox"
    },
    "theme": {
      "toDark": "Modo escuro",
      "toLight": "Modo claro",
      "aria": "Alternar tema"
    },
    "hero": {
      "eyebrow": "AI ENGINEER",
      "name": "Johnny Nordio",
      "tagline": "AI ENGINEER | GENERATIVE AI SPECIALIST | LLM SYSTEMS ARCHITECT",
      "location": "Curitiba - PR | Disponível para remoto internacional",
      "ctaPrimary": "Falar por e-mail",
      "ctaSecondary": "Ver projetos",
      "ctaLinkedin": "LinkedIn",
      "note": "Parte do trabalho está anonimizada (NDA). Detalhes sob demanda.",
      "panelTitle": "Foco",
      "panelTitle2": "O que eu construo",
      "focus": [
        "LLMs",
        "RAG",
        "Agentes",
        "LLMOps",
        "Fine-tuning (LoRA/PEFT)",
        "APIs & Integrações"
      ],
      "build": [
        "Pipelines de RAG end-to-end (ingestão → embeddings → vetores → geração)",
        "Avaliação, monitoramento e guardrails para LLMs",
        "Integração de IA em ERPs e APIs REST",
        "Otimização de desempenho, estabilidade e observabilidade"
      ],
      "panelTitle3": "Pipelines",
      "pipelineHint": "Clique para explorar",
      "pipeline": [
        {
          "id": "ingest",
          "title": "Ingestão",
          "desc": "Documentos, dados e logs",
          "bullets": [
            "Ingestão com normalização + deduplicação",
            "Chunking com estratégia por tipo de dado",
            "Versionamento de fontes e trilha de auditoria"
          ]
        },
        {
          "id": "embed",
          "title": "Embeddings",
          "desc": "Representação semântica",
          "bullets": [
            "Seleção de modelo por domínio/custo/latência",
            "Batching e cache para reduzir custo",
            "Avaliação contínua de recall/precision"
          ]
        },
        {
          "id": "vector",
          "title": "Busca vetorial",
          "desc": "Recuperação com relevância",
          "bullets": [
            "Vector DB (FAISS/Chroma) + filtros",
            "Reranking quando necessário",
            "Observabilidade de consultas e hits"
          ]
        },
        {
          "id": "gen",
          "title": "Geração",
          "desc": "LLM com guardrails",
          "bullets": [
            "Prompts estruturados + context windows",
            "Guardrails e validação de saída",
            "Métricas de qualidade (offline + online)"
          ]
        },
        {
          "id": "ops",
          "title": "LLMOps",
          "desc": "Deploy, monitoramento, avaliação",
          "bullets": [
            "Experiment tracking (MLflow)",
            "Canary/rollback e segurança",
            "Monitoramento de drift e regressões"
          ]
        }
      ],
      "featureTitle": "Case studies em destaque",
      "featureSub": "Clique para abrir um deep-dive rápido (problema, abordagem, impacto).",
      "featureHint": "Dica: Ctrl/Cmd+K para buscar seções, projetos e links.",
      "featuredProjectIds": [
        "erp-crm",
        "rag",
        "agents"
      ]
    },
    "sections": {
      "aboutTitle": "Resumo",
      "aboutSub": "Pragmatismo, produção e qualidade.",
      "skillsTitle": "Competências",
      "skillsSub": "Arquitetura, implementação e entrega.",
      "projectsTitle": "Projetos (seleção)",
      "projectsSub": "Estudos de caso (NDA-friendly) para entender rápido.",
      "experienceTitle": "Experiência & Contribuições",
      "experienceSub": "O que foi entregue, melhorado e estabilizado.",
      "educationTitle": "Formação",
      "educationSub": "IA e engenharia de software com foco em aplicação prática.",
      "contactTitle": "Contato",
      "contactSub": "Melhor: e-mail. Rápido: WhatsApp.",
      "labTitle": "Arquiteturas em ação",
      "labSub": "Um mapa interativo dos blocos que mais uso em produção (RAG, agentes, avaliação e LLMOps).",
      "toolboxTitle": "Toolbox",
      "toolboxSub": "Clique em um item para destacar os projetos que realmente usam aquela peça."
    },
    "about": [
      "Engenheiro de Inteligência Artificial com foco em IA Generativa, Large Language Models (LLMs) e arquiteturas de Retrieval-Augmented Generation (RAG). Experiência em construir pipelines end-to-end e integrar IA em sistemas corporativos (ERP, APIs REST e plataformas Lakehouse).",
      "Atuação prática com fine-tuning (LoRA/PEFT), embeddings, vector databases, agentes multi-step e LLMOps. Trabalho com rigor de engenharia: observabilidade, testes, tratamento de erros e foco em estabilidade e latência.",
      "Parte do portfólio está descrita como estudos de caso anonimizados (NDA-friendly). Posso compartilhar detalhes técnicos adicionais sob demanda."
    ],
    "skills": [
      {
        "group": "GenAI & LLMs",
        "items": [
          "RAG",
          "Agentes multi-step",
          "Prompting estruturado",
          "Guardrails",
          "Avaliação & métricas"
        ]
      },
      {
        "group": "Fine-tuning & NLP",
        "items": [
          "LoRA/PEFT",
          "Hugging Face",
          "Tokenização",
          "Benchmarks",
          "Inference pipelines"
        ]
      },
      {
        "group": "Stacks & Tooling",
        "items": [
          "LangChain",
          "LlamaIndex",
          "FAISS",
          "Chroma",
          "Vector search"
        ]
      },
      {
        "group": "Lakehouse & MLOps",
        "items": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Model Serving",
          "Experiment tracking"
        ]
      },
      {
        "group": "Engenharia",
        "items": [
          "Python avançado",
          "APIs REST",
          "Testes",
          "Profiling",
          "Linux"
        ]
      },
      {
        "group": "Entrega em Produção",
        "items": [
          "Observabilidade",
          "Hardening",
          "Rollbacks",
          "Versionamento",
          "Documentação"
        ]
      }
    ],
    "projects": [
      {
        "title": "ERP/CRM Varejo (NDA) | Estabilidade + Integrações",
        "subtitle": "ResiliÃªncia, trilha de auditoria e integraÃ§Ãµes crÃ­ticas em um ERP/CRM desktop (NDA).",
        "highlights": [
          "Hardening de APIs: validaÃ§Ã£o, erros tratados, observabilidade e compatibilidade retroativa",
          "Paridade ERP<->CRM: diagnÃ³stico por rota, contratos e roundtrip de dados consistente",
          "UX guiada para fluxos crÃ­ticos (venda/pagamento) com auditoria ponta a ponta"
        ],
        "stack": [
          "Python",
          "REST APIs",
          "Desktop app",
          "Databases",
          "Observability"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Estudo de caso anonimizado (NDA-friendly). Detalhes técnicos sob demanda.",
        "image": "assets/projects/project-erpcrm.svg",
        "id": "erp-crm",
        "problem": "OperaÃ§Ã£o de varejo nÃ£o tolera instabilidade: uma desconexÃ£o em venda/estoque/fiscal vira retrabalho, inconsistÃªncia e suporte caro.",
        "approach": [
          "Contratos canÃ´nicos de rotas + testes automatizados para capturar regressÃµes antes do release",
          "Camada de rede resiliente (timeout/backoff/fallback) com retries idempotentes para evitar duplicidade de gravaÃ§Ãµes",
          "PersistÃªncia consistente: configuraÃ§Ãµes e estados crÃ­ticos sempre no banco (sem \"estado em memÃ³ria\") + validaÃ§Ãµes de unicidade",
          "Auditoria como trilha de verdade: registrar quem fez o quÃª e quando, com mensagens operacionais e sem vazar segredos",
          "Profiling + otimizaÃ§Ã£o de queries e carregamento lazy para reduzir \"travadas\" em abas pesadas"
        ],
        "impact": [
          "Comportamento previsÃ­vel em produÃ§Ã£o: menos falhas intermitentes e reconexÃ£o segura",
          "Integridade de dados: ERP -> API -> CRM sem perda de campos e com rastreabilidade",
          "OperaÃ§Ã£o mais simples: diagnÃ³stico mais rÃ¡pido e releases mais seguros"
        ]
      },
      {
        "title": "Enterprise RAG System",
        "subtitle": "Pipeline completo: ingestão → embeddings → armazenamento vetorial → geração.",
        "highlights": [
          "IngestÃ£o versionada: dedup + metadados + chunking por estrutura",
          "RecuperaÃ§Ã£o hÃ­brida: filtros + vetores + reranking, com cache e observabilidade",
          "Qualidade em produÃ§Ã£o: suites de avaliaÃ§Ã£o + guardrails + respostas com evidÃªncias"
        ],
        "stack": [
          "RAG",
          "Embeddings",
          "FAISS/Chroma",
          "LLMOps",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Detalhes de dados e documentos são variáveis por domínio (ajuste rápido por caso).",
        "image": "assets/projects/project-rag.svg",
        "id": "rag",
        "problem": "RAG \"naive\" quebra em produÃ§Ã£o: documentos mudam, a recuperaÃ§Ã£o traz ruÃ­do e ninguÃ©m mede qualidade, gerando respostas erradas com confianÃ§a.",
        "approach": [
          "Pipeline de ingestÃ£o incremental com versionamento de fontes, deduplicaÃ§Ã£o e metadados",
          "Chunking adaptativo por tipo de documento (tÃ­tulo/seÃ§Ã£o/tabela) + normalizaÃ§Ã£o",
          "RecuperaÃ§Ã£o com vetores + filtros, reranking e tuning por recall/precision",
          "AvaliaÃ§Ã£o contÃ­nua (golden set) + gates de regressÃ£o antes de mudanÃ§as de prompt/modelo",
          "Guardrails: schemas, redaction de PII, citaÃ§Ãµes obrigatÃ³rias e controles de custo/latÃªncia"
        ],
        "impact": [
          "Respostas mais confiÃ¡veis e auditÃ¡veis (com evidÃªncias/citaÃ§Ãµes)",
          "Menos risco de alucinaÃ§Ã£o e regressÃµes silenciosas",
          "Loop de melhoria contÃ­nua: medir -> ajustar -> revalidar"
        ]
      },
      {
        "title": "AI Agent Workflows",
        "subtitle": "Agentes autônomos integrados a ferramentas e APIs externas com segurança.",
        "highlights": [
          "Tool-calling seguro: schemas, allowlist, budgets/timeouts e validaÃ§Ã£o de I/O",
          "OrquestraÃ§Ã£o determinÃ­stica: estado explÃ­cito, logs Ãºteis e replay de execuÃ§Ãµes",
          "AvaliaÃ§Ã£o por cenÃ¡rios + regressÃ£o: agentes tratÃ¡veis como software"
        ],
        "stack": [
          "Agents",
          "Tool calling",
          "Guardrails",
          "APIs",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Foco em robustez: execução controlada, logs úteis e falhas previsíveis.",
        "image": "assets/projects/project-agents.svg",
        "id": "agents",
        "problem": "Agentes que chamam ferramentas tÃªm efeitos colaterais reais; sem limites, ficam imprevisÃ­veis, inseguros e difÃ­ceis de depurar.",
        "approach": [
          "Design de ferramentas com contratos (schemas) e validaÃ§Ã£o rigorosa de inputs/outputs",
          "PolÃ­ticas de seguranÃ§a: allowlists, budgets/timeouts, rate limits e aprovaÃ§Ã£o humana para aÃ§Ãµes sensÃ­veis",
          "OrquestraÃ§Ã£o multi-step com estado explÃ­cito, idempotÃªncia e logs por etapa",
          "Test harness com cenÃ¡rios reais + replay para depuraÃ§Ã£o e regressÃ£o",
          "Observabilidade: tracing por step, custo/latÃªncia e erros acionÃ¡veis"
        ],
        "impact": [
          "Agentes previsÃ­veis, testÃ¡veis e fÃ¡ceis de operar",
          "Menos risco operacional em integraÃ§Ãµes com sistemas externos",
          "Time-to-market mais rÃ¡pido para novos workflows e ferramentas"
        ]
      },
      {
        "title": "Lakehouse LLMOps (Databricks)",
        "subtitle": "Integração de dados + rastreabilidade de modelos em ambiente corporativo.",
        "highlights": [
          "Lineage e reprodutibilidade: Delta Lake + checks de qualidade de dados",
          "GovernanÃ§a de modelos: MLflow tracking/registry + deploy canary/rollback",
          "OperaÃ§Ã£o: mÃ©tricas online + alertas (sem nÃºmeros inventados)"
        ],
        "stack": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Serving",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Padrões prontos para monitoramento, versionamento e entrega contínua.",
        "image": "assets/projects/project-lakehouse.svg",
        "id": "lakehouse",
        "problem": "Sem governanÃ§a, o ciclo de dados/modelos vira caixa-preta: difÃ­cil reproduzir, auditar e operar sob pressÃ£o.",
        "approach": [
          "Pipelines Lakehouse com versionamento, validaÃ§Ãµes e trilha de lineage",
          "MLflow para tracking/registro/versionamento, com artefatos reproduzÃ­veis",
          "Deploy com canary + rollback e monitoramento por custo/latÃªncia/qualidade",
          "IntegraÃ§Ã£o com APIs/sistemas legados e controles de acesso",
          "OperaÃ§Ã£o contÃ­nua: alertas, playbooks e rotinas de validaÃ§Ã£o"
        ],
        "impact": [
          "Entrega controlada e auditÃ¡vel do ciclo inteiro",
          "Resposta mais rÃ¡pida a incidentes e regressÃµes",
          "Base pronta para escalar para mÃºltiplos domÃ­nios/equipes"
        ]
      },
      {
        "id": "finetune",
        "title": "Fine-tuning de Transformers (LoRA/PEFT)",
        "subtitle": "Ajuste fino com foco em qualidade, custo e governança de experimentos.",
        "problem": "Modelos base nÃ£o refletem linguagem de domÃ­nio; fine-tuning sem avaliaÃ§Ã£o vira overfitting e regressÃµes difÃ­ceis de perceber.",
        "approach": [
          "Curadoria/limpeza/segmentaÃ§Ã£o de datasets e instruÃ§Ãµes por objetivo",
          "LoRA/PEFT com experimentos reproduzÃ­veis + versionamento de dados e configs",
          "Benchmarks e avaliaÃ§Ã£o qualitativa+quantitativa, com baseline e ablaÃ§Ãµes",
          "Pipelines de inferÃªncia com atenÃ§Ã£o a latÃªncia/custo + monitoraÃ§Ã£o",
          "Gates de release e rollback quando degrada"
        ],
        "impact": [
          "Modelos alinhados ao domÃ­nio com risco controlado",
          "Ciclo de iteraÃ§Ã£o mais rÃ¡pido e seguro",
          "Entrega pronta para produÃ§Ã£o com rastreabilidade"
        ],
        "highlights": [
          "Curadoria de dados + LoRA/PEFT com rastreabilidade e ablaÃ§Ã£o",
          "AvaliaÃ§Ã£o rigorosa: qualidade, seguranÃ§a e regressÃ£o antes do deploy",
          "InferÃªncia: otimizaÃ§Ã£o de custo/latÃªncia (batching/cache/quantizaÃ§Ã£o quando aplicÃ¡vel)"
        ],
        "stack": [
          "Transformers",
          "LoRA/PEFT",
          "Hugging Face",
          "Eval",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Detalhes de datasets/modelos dependem do caso de uso.",
        "image": "assets/projects/project-generic.svg"
      },
      {
        "id": "eval",
        "title": "Avaliação & Observabilidade de LLMs",
        "subtitle": "Métricas, suites de teste e monitoramento para evitar regressões.",
        "problem": "LLMs degradam silenciosamente em produÃ§Ã£o; sem observabilidade, vocÃª sÃ³ descobre quando o usuÃ¡rio reclama.",
        "approach": [
          "Golden set + testes automÃ¡ticos por rota/caso (CI/CD) para detectar regressÃµes cedo",
          "MÃ©tricas online: latÃªncia, custo, erro e qualidade percebida, com sampling e traces",
          "Tracing E2E: request -> retrieval -> prompt -> resposta (sem vazar PII)",
          "Guardrails: schema, polÃ­ticas de dados e validaÃ§Ãµes por contexto",
          "Processo de release: checklist + canary + rollback e playbooks de incidente"
        ],
        "impact": [
          "DetecÃ§Ã£o precoce e debug mais rÃ¡pido",
          "Sistemas mais previsÃ­veis e confiÃ¡veis",
          "Releases mais seguros (menos surpresas)"
        ],
        "highlights": [
          "Golden set + testes automÃ¡ticos por rota/caso (CI/CD)",
          "Tracing E2E com custo/latÃªncia, sem vazamento de PII",
          "Alertas + playbooks para incidentes e regressÃµes"
        ],
        "stack": [
          "LLMOps",
          "Observability",
          "Testing",
          "Python",
          "APIs"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Sem números inventados: métricas específicas variam por cliente e contexto.",
        "image": "assets/projects/project-lakehouse.svg"
      }
    ],
    "labels": {
      "repo": "Repo",
      "demo": "Demo",
      "writeup": "Writeup",
      "caseStudy": "Estudo de caso",
      "problem": "Problema",
      "approach": "Abordagem",
      "impact": "Impacto",
      "highlights": "Destaques",
      "stack": "Stack"
    },
    "experience": [
      {
        "when": "Open Source AI",
        "title": "Contribuições em OpenShift AI / InstructLab",
        "org": "Ecossistema Red Hat (conforme CV)",
        "bullets": [
          "Otimização e integração de modelos generativos em ambiente corporativo",
          "Práticas de engenharia: observabilidade, hardening e qualidade de entrega"
        ]
      },
      {
        "when": "NLP / Fine-tuning",
        "title": "Fine-tuning e pipelines (ecossistema Hugging Face)",
        "org": "Projetos e benchmarks de avaliação (conforme CV)",
        "bullets": [
          "Experimentos com LoRA/PEFT e avaliação de qualidade",
          "Pipelines de inferência com foco em desempenho e confiabilidade"
        ]
      },
      {
        "when": "Dados / Automação",
        "title": "Automação de fluxos corporativos + Lakehouse",
        "org": "Volk do Brasil (conforme CV)",
        "bullets": [
          "Automação com Python e integração de dados",
          "Aplicação de IA em plataforma Databricks (Delta/MLflow)"
        ]
      },
      {
        "when": "Embedded / Linux",
        "title": "Linux OEM e sistemas críticos",
        "org": "Perkons & Policorp (conforme CV)",
        "bullets": [
          "Customização de distribuições Linux OEM",
          "Engenharia embarcada e software mission-critical"
        ]
      }
    ],
    "education": [
      {
        "title": "Pós-graduação em Inteligência Artificial",
        "org": "UTFPR",
        "year": "2025"
      },
      {
        "title": "Pós-graduação em Engenharia de Software",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Tecnólogo em Análise e Desenvolvimento de Sistemas",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Pós-graduação em IA Generativa Aplicada",
        "org": "UTFPR",
        "year": "Início Abr/2026",
        "note": "Linha de estudo aplicada em GenAI e LLM systems."
      }
    ],
    "quickLinks": [
      {
        "label": "LinkedIn",
        "href": "https://br.linkedin.com/in/johnny-nordio-533769251",
        "external": true
      },
      {
        "label": "GitHub",
        "href": "https://github.com/Nordio1",
        "external": true
      },
      {
        "label": "WhatsApp",
        "href": "https://wa.me/5541995879232",
        "external": true
      },
      {
        "label": "Email",
        "href": "mailto:mrnordio@icloud.com",
        "external": false
      }
    ],
    "contact": {
      "cardTitle": "Fale comigo",
      "cardSub": "Posso compartilhar writeups técnicos e detalhes dos estudos de caso.",
      "phoneCta": "WhatsApp",
      "linkedinCta": "LinkedIn",
      "quickTitle": "Links rápidos",
      "quickNote": "Links úteis para contato e portfólio.",
      "privacy": "Página pública. Sem scripts de tracking."
    },
    "footer": {
      "backTop": "Voltar ao topo"
    },
    "lab": {
      "legend": [
        {
          "label": "RAG",
          "hint": "Recuperação + geração"
        },
        {
          "label": "Agentes",
          "hint": "Tool-calling multi-step"
        },
        {
          "label": "Avaliação",
          "hint": "Qualidade e regressão"
        },
        {
          "label": "LLMOps",
          "hint": "Deploy e monitoramento"
        }
      ],
      "nodes": [
        {
          "id": "sources",
          "label": "Fontes",
          "x": 16,
          "y": 20,
          "title": "Fontes e ingestão",
          "body": "Ponto de partida: documentos, tabelas, eventos e dados operacionais. A chave é consistência e rastreabilidade.",
          "bullets": [
            "Normalização e deduplicação",
            "Controle de versões de dados",
            "Trilha de auditoria (o que entrou e quando)"
          ],
          "links": [
            "chunking"
          ]
        },
        {
          "id": "chunking",
          "label": "Chunking",
          "x": 38,
          "y": 30,
          "title": "Chunking e indexação",
          "body": "Separar conteúdo em partes recuperáveis aumenta a qualidade do RAG. Estratégias mudam por domínio.",
          "bullets": [
            "Chunking por estrutura (título/seção/tabela)",
            "Metadados para filtros",
            "Testes de recall/precision"
          ],
          "links": [
            "vectors",
            "eval"
          ]
        },
        {
          "id": "vectors",
          "label": "Vetores",
          "x": 60,
          "y": 18,
          "title": "Embeddings + vector store",
          "body": "Embeddings traduzem texto em vetores. O index precisa ser rápido, consistente e observável.",
          "bullets": [
            "FAISS/Chroma e filtros",
            "Cache e batching",
            "Reranking quando necessário"
          ],
          "links": [
            "rag"
          ]
        },
        {
          "id": "rag",
          "label": "RAG",
          "x": 72,
          "y": 42,
          "title": "RAG (retrieval + geração)",
          "body": "Resposta com base em evidências recuperadas. O objetivo é reduzir alucinação e aumentar precisão.",
          "bullets": [
            "Contexto citado/ancorado",
            "Prompts estruturados",
            "Fallbacks e limites"
          ],
          "links": [
            "guardrails",
            "eval"
          ]
        },
        {
          "id": "agents",
          "label": "Agentes",
          "x": 22,
          "y": 58,
          "title": "Agentes com ferramentas",
          "body": "Agentes chamam ferramentas/APIs. O segredo é previsibilidade: limites, validação e logs úteis.",
          "bullets": [
            "Tool-calling com validação",
            "Execução multi-step controlada",
            "Erros previsíveis e rastreáveis"
          ],
          "links": [
            "guardrails",
            "ops"
          ]
        },
        {
          "id": "guardrails",
          "label": "Guardrails",
          "x": 52,
          "y": 60,
          "title": "Guardrails e segurança",
          "body": "Regras para evitar saídas perigosas e reduzir comportamento inesperado em produção.",
          "bullets": [
            "Validação de entrada/saída",
            "Políticas de dados e PII",
            "Rate limits e timeouts"
          ],
          "links": [
            "eval"
          ]
        },
        {
          "id": "eval",
          "label": "Avaliação",
          "x": 78,
          "y": 70,
          "title": "Avaliação contínua",
          "body": "Sem avaliação, sistema degrada. O foco é criar testes e métricas que detectem regressão cedo.",
          "bullets": [
            "Suites offline (golden set)",
            "Métricas online (qualidade/latência)",
            "Observabilidade e alertas"
          ],
          "links": [
            "ops"
          ]
        },
        {
          "id": "ops",
          "label": "LLMOps",
          "x": 90,
          "y": 56,
          "title": "LLMOps (deploy e monitoramento)",
          "body": "Entrega com controle: versionamento, canary, rollback e monitoramento por custo/latência/qualidade.",
          "bullets": [
            "MLflow / tracking",
            "Deploy seguro (canary/rollback)",
            "Monitoramento + auditoria"
          ],
          "links": []
        }
      ]
    },
    "toolbox": {
      "clear": "Limpar",
      "help": "Dica: Shift+clique para selecionar mais de um item.",
      "countLabel": "projetos"
    },
    "cmdk": {
      "open": "Comandos",
      "title": "Comandos",
      "placeholder": "Buscar seÃ§Ãµes, projetos e links...",
      "hint": "Use â/â e Enter. Pressione Ctrl+K para abrir de qualquer lugar.",
      "sectionHint": "Ir para seção",
      "actionHint": "Ação rápida",
      "toggleTheme": "Alternar tema",
      "email": "E-mail",
      "whatsapp": "WhatsApp",
      "kinds": {
        "section": "Seção",
        "project": "Projeto",
        "link": "Link",
        "action": "Ação"
      }
    }
  },
  "en": {
    "meta": {
      "title": "Johnny Nordio | AI Engineer",
      "description": "Artificial Intelligence Engineer focused on Generative AI, LLMs, RAG, agents, and LLMOps.",
      "ogDescription": "Generative AI • LLMs • RAG • Agents • LLMOps"
    },
    "profile": {
      "email": "mrnordio@icloud.com",
      "whatsapp": "https://wa.me/5541995879232",
      "github": "https://github.com/Nordio1",
      "linkedin": "https://br.linkedin.com/in/johnny-nordio-533769251"
    },
    "nav": {
      "about": "Summary",
      "skills": "Skills",
      "projects": "Projects",
      "experience": "Experience",
      "education": "Education",
      "contact": "Contact",
      "lab": "Systems",
      "toolbox": "Toolbox"
    },
    "theme": {
      "toDark": "Dark mode",
      "toLight": "Light mode",
      "aria": "Toggle theme"
    },
    "hero": {
      "eyebrow": "AI ENGINEER",
      "name": "Johnny Nordio",
      "tagline": "AI ENGINEER | GENERATIVE AI SPECIALIST | LLM SYSTEMS ARCHITECT",
      "location": "Curitiba, Brazil | Open to Global Remote Roles",
      "ctaPrimary": "Email me",
      "ctaSecondary": "View projects",
      "ctaLinkedin": "LinkedIn",
      "note": "Some work is anonymized (NDA-friendly). Details available on request.",
      "panelTitle": "Focus",
      "panelTitle2": "What I build",
      "focus": [
        "LLMs",
        "RAG",
        "Agents",
        "LLMOps",
        "Fine-tuning (LoRA/PEFT)",
        "APIs & Integrations"
      ],
      "build": [
        "End-to-end RAG pipelines (ingestion → embeddings → vector store → generation)",
        "LLM evaluation, monitoring, and guardrails",
        "AI integration into enterprise ERPs and REST APIs",
        "Performance, stability, and observability improvements"
      ],
      "panelTitle3": "Pipelines",
      "pipelineHint": "Click to explore",
      "pipeline": [
        {
          "id": "ingest",
          "title": "Ingestion",
          "desc": "Docs, data, logs",
          "bullets": [
            "Ingestion with normalization + deduplication",
            "Chunking strategies per data type",
            "Source versioning and audit trail"
          ]
        },
        {
          "id": "embed",
          "title": "Embeddings",
          "desc": "Semantic representations",
          "bullets": [
            "Model selection by domain/cost/latency",
            "Batching and caching to reduce cost",
            "Continuous recall/precision evaluation"
          ]
        },
        {
          "id": "vector",
          "title": "Vector search",
          "desc": "Retrieval with relevance",
          "bullets": [
            "Vector DB (FAISS/Chroma) + filters",
            "Reranking when needed",
            "Query/hit observability"
          ]
        },
        {
          "id": "gen",
          "title": "Generation",
          "desc": "LLM with guardrails",
          "bullets": [
            "Structured prompting + context windows",
            "Output validation and guardrails",
            "Quality metrics (offline + online)"
          ]
        },
        {
          "id": "ops",
          "title": "LLMOps",
          "desc": "Deploy, monitoring, evaluation",
          "bullets": [
            "Experiment tracking (MLflow)",
            "Canary/rollback and security",
            "Drift monitoring and regressions"
          ]
        }
      ],
      "featureTitle": "Featured case studies",
      "featureSub": "Click to open a quick deep-dive (problem, approach, impact).",
      "featureHint": "Tip: Ctrl/Cmd+K to search sections, projects and links.",
      "featuredProjectIds": [
        "erp-crm",
        "rag",
        "agents"
      ]
    },
    "sections": {
      "aboutTitle": "Executive Summary",
      "aboutSub": "Pragmatic, production-focused, quality-driven.",
      "skillsTitle": "Strategic Expertise",
      "skillsSub": "Architecture, implementation, and delivery.",
      "projectsTitle": "Selected Projects",
      "projectsSub": "NDA-friendly case studies you can scan in 60 seconds.",
      "experienceTitle": "Experience & Contributions",
      "experienceSub": "What shipped, what improved, and what stabilized.",
      "educationTitle": "Education",
      "educationSub": "AI and software engineering with a hands-on bias.",
      "contactTitle": "Contact",
      "contactSub": "Best: email. Fast: WhatsApp.",
      "labTitle": "Architectures in action",
      "labSub": "An interactive map of the building blocks I ship in production (RAG, agents, evaluation, LLMOps).",
      "toolboxTitle": "Toolbox",
      "toolboxSub": "Click a tag to highlight projects that actually use it."
    },
    "about": [
      "Artificial Intelligence Engineer focused on Generative AI, Large Language Models (LLMs), and Retrieval-Augmented Generation (RAG) architectures. Experienced in building end-to-end pipelines and integrating AI into enterprise systems (ERP, REST APIs, and Lakehouse platforms).",
      "Hands-on with fine-tuning (LoRA/PEFT), embeddings, vector databases, multi-step agents, and LLMOps. Strong engineering rigor: observability, testing, error handling, and a relentless focus on stability and latency.",
      "Some portfolio items are described as anonymized case studies (NDA-friendly). I can share deeper technical details on request."
    ],
    "skills": [
      {
        "group": "GenAI & LLMs",
        "items": [
          "RAG",
          "Multi-step agents",
          "Structured prompting",
          "Guardrails",
          "Evaluation & metrics"
        ]
      },
      {
        "group": "Fine-tuning & NLP",
        "items": [
          "LoRA/PEFT",
          "Hugging Face",
          "Tokenization",
          "Benchmarks",
          "Inference pipelines"
        ]
      },
      {
        "group": "Stacks & Tooling",
        "items": [
          "LangChain",
          "LlamaIndex",
          "FAISS",
          "Chroma",
          "Vector search"
        ]
      },
      {
        "group": "Lakehouse & MLOps",
        "items": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Model Serving",
          "Experiment tracking"
        ]
      },
      {
        "group": "Engineering",
        "items": [
          "Advanced Python",
          "REST APIs",
          "Testing",
          "Profiling",
          "Linux"
        ]
      },
      {
        "group": "Production Delivery",
        "items": [
          "Observability",
          "Hardening",
          "Rollbacks",
          "Versioning",
          "Docs"
        ]
      }
    ],
    "projects": [
      {
        "title": "Retail ERP/CRM (NDA) | Stability + Integrations",
        "subtitle": "Resilience, audit trail, and critical integrations in a desktop ERP/CRM (NDA).",
        "highlights": [
          "API hardening: validation, explicit errors, observability, and backwards-compatible contracts",
          "ERP<->CRM parity: route-level diagnostics, contracts, and consistent data roundtrip",
          "Guided critical flows (sales/payments) with end-to-end auditing"
        ],
        "stack": [
          "Python",
          "REST APIs",
          "Desktop app",
          "Databases",
          "Observability"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Anonymized case study (NDA-friendly). Deeper technical details on request.",
        "image": "assets/projects/project-erpcrm.svg",
        "id": "erp-crm",
        "problem": "Retail operations cannot tolerate instability: a disconnect during sales/stock/fiscal flows turns into rework, inconsistency, and expensive support.",
        "approach": [
          "Canonical API contracts + automated route checks to catch regressions before release",
          "Resilient networking (timeouts/backoff/fallback) with idempotent retries to avoid duplicate writes",
          "Consistent persistence: critical configs/state always in the database (no \"in-memory state\") + uniqueness validation",
          "Audit trail as source of truth: who did what/when, with operational messages and no secret leakage",
          "Profiling + query and lazy-load optimization to reduce first-click freezes on heavy screens"
        ],
        "impact": [
          "More predictable production behavior: fewer intermittent failures and safer reconnection",
          "Data integrity: ERP -> API -> CRM roundtrip without losing fields, with traceability",
          "Simpler operations: faster diagnosis and safer releases"
        ]
      },
      {
        "title": "Enterprise RAG System",
        "subtitle": "Full pipeline: ingestion → embeddings → vector store → generation.",
        "highlights": [
          "Versioned ingestion: dedup + metadata + structure-aware chunking",
          "Hybrid retrieval: filters + vectors + reranking, with cache + observability",
          "Production quality: evaluation suites + guardrails + evidence-backed answers"
        ],
        "stack": [
          "RAG",
          "Embeddings",
          "FAISS/Chroma",
          "LLMOps",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Data sources and documents vary by domain (fast adaptation per use case).",
        "image": "assets/projects/project-rag.svg",
        "id": "rag",
        "problem": "Naive RAG breaks in production: documents change, retrieval brings noise, and nobody measures quality, leading to confident-but-wrong answers.",
        "approach": [
          "Incremental ingestion pipeline with source versioning, deduplication, and metadata",
          "Adaptive chunking per doc type (headings/sections/tables) + normalization",
          "Retrieval with vectors + filters, reranking, and tuning by recall/precision",
          "Continuous evaluation (golden set) + regression gates before prompt/model changes",
          "Guardrails: schemas, PII redaction, required citations, and cost/latency controls"
        ],
        "impact": [
          "More trustworthy, auditable answers (evidence-backed)",
          "Lower hallucination risk and fewer silent regressions",
          "A measurable improvement loop: measure -> adjust -> re-validate"
        ]
      },
      {
        "title": "AI Agent Workflows",
        "subtitle": "Autonomous agents integrated with tools and external APIs, safely.",
        "highlights": [
          "Safe tool-calling: schemas, allowlists, budgets/timeouts, strict I/O validation",
          "Deterministic orchestration: explicit state, useful logs, and execution replay",
          "Scenario evaluation + regression: agents treated as real software"
        ],
        "stack": [
          "Agents",
          "Tooling",
          "Guardrails",
          "APIs",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Robustness first: controlled execution, useful logs, predictable failures.",
        "image": "assets/projects/project-agents.svg",
        "id": "agents",
        "problem": "Agents that call tools have real side effects; without limits they become unpredictable, unsafe, and hard to debug.",
        "approach": [
          "Tool design with contracts (schemas) and strict input/output validation",
          "Security policies: allowlists, budgets/timeouts, rate limits, and human approval for sensitive actions",
          "Multi-step orchestration with explicit state, idempotency, and step-level logs",
          "Scenario-based test harness + replay for debugging and regression",
          "Observability: step tracing, cost/latency, and actionable errors"
        ],
        "impact": [
          "Agents that behave like software: predictable, testable, operable",
          "Lower operational risk when integrating external systems",
          "Faster time-to-market for new workflows and tools"
        ]
      },
      {
        "title": "Lakehouse LLMOps (Databricks)",
        "subtitle": "Data integration + model traceability in enterprise environments.",
        "highlights": [
          "Lineage + reproducibility: Delta Lake + data quality checks",
          "Model governance: MLflow tracking/registry + canary/rollback",
          "Operational metrics + alerts (no invented numbers)"
        ],
        "stack": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Serving",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Patterns ready for monitoring, versioning, and continuous delivery.",
        "image": "assets/projects/project-lakehouse.svg",
        "id": "lakehouse",
        "problem": "Without governance, the data/model lifecycle becomes a black box: hard to reproduce, audit, and operate under pressure.",
        "approach": [
          "Lakehouse pipelines with versioning, validation, and lineage",
          "MLflow tracking/registry/versioning with reproducible artifacts",
          "Canary + rollback deployment and monitoring by cost/latency/quality",
          "Integration with legacy systems/APIs and access controls",
          "Continuous ops: alerts, playbooks, and validation routines"
        ],
        "impact": [
          "End-to-end delivery that is controlled and auditable",
          "Faster response to incidents and regressions",
          "A foundation that scales across domains/teams"
        ]
      },
      {
        "id": "finetune",
        "title": "Transformer Fine-Tuning (LoRA/PEFT)",
        "subtitle": "Fine-tuning focused on quality, cost, and experiment governance.",
        "problem": "Base models rarely match a domain's language; fine-tuning without evaluation leads to overfitting and hard-to-notice regressions.",
        "approach": [
          "Dataset curation/cleaning/slicing and instruction design per objective",
          "LoRA/PEFT with reproducible experiments + versioned data/configs",
          "Benchmarks and qualitative+quantitative evaluation with baselines and ablations",
          "Inference pipelines with latency/cost awareness + monitoring",
          "Release gates and rollback when quality degrades"
        ],
        "impact": [
          "Domain-aligned models with controlled risk",
          "Faster, safer iteration cycles",
          "Production-ready delivery with traceability"
        ],
        "highlights": [
          "Data curation + LoRA/PEFT with traceability and ablations",
          "Rigorous evaluation: quality, safety, and regression before deployment",
          "Inference: cost/latency optimization (batching/cache/quantization when applicable)"
        ],
        "stack": [
          "Transformers",
          "LoRA/PEFT",
          "Hugging Face",
          "Eval",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Model/dataset details vary by use case.",
        "image": "assets/projects/project-generic.svg"
      },
      {
        "id": "eval",
        "title": "LLM Evaluation & Observability",
        "subtitle": "Metrics, test suites, and monitoring to prevent regressions.",
        "problem": "LLMs degrade silently in production; without observability you only learn when users complain.",
        "approach": [
          "Golden set + route/scenario tests in CI/CD to catch regressions early",
          "Online metrics: latency, cost, errors, and perceived quality with sampling and traces",
          "E2E tracing: request -> retrieval -> prompt -> output (no PII leakage)",
          "Guardrails: schemas, data policies, and context-aware validation",
          "Release process: checklist + canary + rollback and incident playbooks"
        ],
        "impact": [
          "Earlier detection and faster debugging",
          "More predictable, reliable systems",
          "Safer releases with fewer surprises"
        ],
        "highlights": [
          "Golden sets + automated tests per route/scenario (CI/CD)",
          "E2E tracing with cost/latency, without PII leakage",
          "Alerts + playbooks for incidents and regressions"
        ],
        "stack": [
          "LLMOps",
          "Observability",
          "Testing",
          "Python",
          "APIs"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "No fabricated numbers: metrics are context-dependent.",
        "image": "assets/projects/project-lakehouse.svg"
      }
    ],
    "labels": {
      "repo": "Repo",
      "demo": "Demo",
      "writeup": "Writeup",
      "caseStudy": "Case study",
      "problem": "Problem",
      "approach": "Approach",
      "impact": "Impact",
      "highlights": "Highlights",
      "stack": "Stack"
    },
    "experience": [
      {
        "when": "Open Source AI",
        "title": "OpenShift AI / InstructLab contributions",
        "org": "Red Hat ecosystem (per CV)",
        "bullets": [
          "Contributions and improvements focused on GenAI workflows for enterprise use",
          "Hardening: error handling, useful logs, validations, predictable behavior",
          "Performance/latency improvements and fewer intermittent pipeline failures",
          "Engineering discipline: tests, release notes, sustainable maintenance"
        ]
      },
      {
        "when": "NLP / Fine-tuning",
        "title": "Fine-tuning and inference pipelines (Hugging Face ecosystem)",
        "org": "Projects and evaluation benchmarks (per CV)",
        "bullets": [
          "LoRA/PEFT experiments and quality evaluation",
          "Inference pipelines with performance and reliability focus"
        ]
      },
      {
        "when": "Data / Automation",
        "title": "Enterprise workflow automation + Lakehouse",
        "org": "Volk do Brasil (per CV)",
        "bullets": [
          "Python automation and data integration across systems",
          "Lakehouse pipelines (Delta) with traceability and data quality",
          "MLflow for experiment tracking/versioning and governance",
          "Integration with enterprise APIs and legacy systems"
        ]
      },
      {
        "when": "Embedded / Linux",
        "title": "Linux OEM and mission-critical systems",
        "org": "Perkons & Policorp (per CV)",
        "bullets": [
          "Linux OEM distribution customization and build/deploy processes",
          "Embedded engineering and hardware integrations when applicable",
          "Stability focus: diagnosis, logs, safe fixes",
          "Tooling and processes for critical software maintenance"
        ]
      }
    ],
    "education": [
      {
        "title": "Postgraduate Degree in Artificial Intelligence",
        "org": "UTFPR",
        "year": "2025"
      },
      {
        "title": "Postgraduate Degree in Software Engineering",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Technologist Degree in Systems Analysis and Development",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Postgraduate Degree in Applied Generative AI",
        "org": "UTFPR",
        "year": "Starting Apr/2026",
        "note": "Applied track for GenAI and LLM systems."
      }
    ],
    "quickLinks": [
      {
        "label": "LinkedIn",
        "href": "https://br.linkedin.com/in/johnny-nordio-533769251",
        "external": true
      },
      {
        "label": "GitHub",
        "href": "https://github.com/Nordio1",
        "external": true
      },
      {
        "label": "WhatsApp",
        "href": "https://wa.me/5541995879232",
        "external": true
      },
      {
        "label": "Email",
        "href": "mailto:mrnordio@icloud.com",
        "external": false
      }
    ],
    "contact": {
      "cardTitle": "Get in touch",
      "cardSub": "Happy to share deeper technical writeups and case study details.",
      "phoneCta": "WhatsApp",
      "linkedinCta": "LinkedIn",
      "quickTitle": "Quick links",
      "quickNote": "Useful links for contact and work.",
      "privacy": "Public page. No tracking scripts."
    },
    "footer": {
      "backTop": "Back to top"
    },
    "lab": {
      "legend": [
        {
          "label": "RAG",
          "hint": "Retrieval + generation"
        },
        {
          "label": "Agents",
          "hint": "Multi-step tool calling"
        },
        {
          "label": "Evaluation",
          "hint": "Quality and regressions"
        },
        {
          "label": "LLMOps",
          "hint": "Deploy and monitoring"
        }
      ],
      "nodes": [
        {
          "id": "sources",
          "label": "Sources",
          "x": 16,
          "y": 20,
          "title": "Sources and ingestion",
          "body": "Starting point: documents, tables, events, operational data. The key is consistency and traceability.",
          "bullets": [
            "Normalization and deduplication",
            "Data versioning",
            "Audit trail (what/when)"
          ],
          "links": [
            "chunking"
          ]
        },
        {
          "id": "chunking",
          "label": "Chunking",
          "x": 38,
          "y": 30,
          "title": "Chunking and indexing",
          "body": "Splitting content into retrievable units improves RAG quality. Strategies vary by domain.",
          "bullets": [
            "Structure-aware chunking",
            "Metadata for filters",
            "Recall/precision testing"
          ],
          "links": [
            "vectors",
            "eval"
          ]
        },
        {
          "id": "vectors",
          "label": "Vectors",
          "x": 60,
          "y": 18,
          "title": "Embeddings + vector store",
          "body": "Embeddings turn text into vectors. Indexes must be fast, consistent, and observable.",
          "bullets": [
            "FAISS/Chroma and filters",
            "Caching and batching",
            "Reranking when needed"
          ],
          "links": [
            "rag"
          ]
        },
        {
          "id": "rag",
          "label": "RAG",
          "x": 72,
          "y": 42,
          "title": "RAG (retrieval + generation)",
          "body": "Evidence-grounded answers. Goal: reduce hallucination and increase accuracy.",
          "bullets": [
            "Anchored context",
            "Structured prompts",
            "Fallbacks and limits"
          ],
          "links": [
            "guardrails",
            "eval"
          ]
        },
        {
          "id": "agents",
          "label": "Agents",
          "x": 22,
          "y": 58,
          "title": "Tool-enabled agents",
          "body": "Agents call tools/APIs. The secret is predictability: limits, validation, and useful logs.",
          "bullets": [
            "Tool calling with validation",
            "Controlled multi-step execution",
            "Predictable failures"
          ],
          "links": [
            "guardrails",
            "ops"
          ]
        },
        {
          "id": "guardrails",
          "label": "Guardrails",
          "x": 52,
          "y": 60,
          "title": "Guardrails and safety",
          "body": "Policies to reduce unsafe outputs and unexpected behavior in production.",
          "bullets": [
            "I/O validation",
            "Data/PII policies",
            "Rate limits and timeouts"
          ],
          "links": [
            "eval"
          ]
        },
        {
          "id": "eval",
          "label": "Evaluation",
          "x": 78,
          "y": 70,
          "title": "Continuous evaluation",
          "body": "Without evaluation, systems degrade. Focus: tests and metrics that catch regressions early.",
          "bullets": [
            "Offline suites (golden set)",
            "Online metrics (quality/latency)",
            "Observability and alerts"
          ],
          "links": [
            "ops"
          ]
        },
        {
          "id": "ops",
          "label": "LLMOps",
          "x": 90,
          "y": 56,
          "title": "LLMOps (deploy and monitoring)",
          "body": "Delivery with control: versioning, canary, rollback and monitoring for cost/latency/quality.",
          "bullets": [
            "MLflow / tracking",
            "Safe deploy (canary/rollback)",
            "Monitoring + audit trail"
          ],
          "links": []
        }
      ]
    },
    "toolbox": {
      "clear": "Clear",
      "help": "Tip: Shift+click to multi-select.",
      "countLabel": "projects"
    },
    "cmdk": {
      "open": "Cmd+K",
      "title": "Command palette",
      "placeholder": "Search sections, projects and links...",
      "hint": "Use ↑/↓ and Enter. Press Ctrl+K (or Cmd+K) from anywhere.",
      "sectionHint": "Jump to section",
      "actionHint": "Quick action",
      "toggleTheme": "Toggle theme",
      "email": "Email",
      "whatsapp": "WhatsApp",
      "kinds": {
        "section": "Section",
        "project": "Project",
        "link": "Link",
        "action": "Action"
      }
    }
  }
}
