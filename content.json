{
  "pt": {
    "meta": {
      "title": "Johnny Nordio | Engenheiro de IA",
      "description": "Engenheiro de Inteligência Artificial focado em IA Generativa, LLMs, RAG, agentes e LLMOps.",
      "ogDescription": "IA Generativa • LLMs • RAG • Agentes • LLMOps"
    },
    "profile": {
      "email": "mrnordio@icloud.com",
      "whatsapp": "https://wa.me/5541995879232",
      "github": "https://github.com/Nordio1",
      "linkedin": "https://br.linkedin.com/in/johnny-nordio-533769251"
    },
    "nav": {
      "about": "Resumo",
      "skills": "Competências",
      "projects": "Projetos",
      "experience": "Experiência",
      "education": "Formação",
      "contact": "Contato",
      "lab": "Arquiteturas",
      "toolbox": "Toolbox"
    },
    "theme": {
      "toDark": "Modo escuro",
      "toLight": "Modo claro",
      "aria": "Alternar tema"
    },
    "hero": {
      "eyebrow": "AI ENGINEER",
      "name": "Johnny Nordio",
      "tagline": "AI ENGINEER | GENERATIVE AI SPECIALIST | LLM SYSTEMS ARCHITECT",
      "location": "Curitiba - PR | Disponível para remoto internacional",
      "ctaPrimary": "Falar por e-mail",
      "ctaSecondary": "Ver projetos",
      "ctaLinkedin": "LinkedIn",
      "note": "Parte do trabalho está anonimizada (NDA). Detalhes sob demanda.",
      "panelTitle": "Foco",
      "panelTitle2": "O que eu construo",
      "focus": [
        "LLMs",
        "RAG",
        "Agentes",
        "LLMOps",
        "Fine-tuning (LoRA/PEFT)",
        "APIs & Integrações"
      ],
      "build": [
        "Pipelines de RAG end-to-end (ingestão → embeddings → vetores → geração)",
        "Avaliação, monitoramento e guardrails para LLMs",
        "Integração de IA em ERPs e APIs REST",
        "Otimização de desempenho, estabilidade e observabilidade"
      ],
      "panelTitle3": "Pipelines",
      "pipelineHint": "Clique para explorar",
      "pipeline": [
        {
          "id": "ingest",
          "title": "Ingestão",
          "desc": "Documentos, dados e logs",
          "bullets": [
            "Ingestão com normalização + deduplicação",
            "Chunking com estratégia por tipo de dado",
            "Versionamento de fontes e trilha de auditoria"
          ]
        },
        {
          "id": "embed",
          "title": "Embeddings",
          "desc": "Representação semântica",
          "bullets": [
            "Seleção de modelo por domínio/custo/latência",
            "Batching e cache para reduzir custo",
            "Avaliação contínua de recall/precision"
          ]
        },
        {
          "id": "vector",
          "title": "Busca vetorial",
          "desc": "Recuperação com relevância",
          "bullets": [
            "Vector DB (FAISS/Chroma) + filtros",
            "Reranking quando necessário",
            "Observabilidade de consultas e hits"
          ]
        },
        {
          "id": "gen",
          "title": "Geração",
          "desc": "LLM com guardrails",
          "bullets": [
            "Prompts estruturados + context windows",
            "Guardrails e validação de saída",
            "Métricas de qualidade (offline + online)"
          ]
        },
        {
          "id": "ops",
          "title": "LLMOps",
          "desc": "Deploy, monitoramento, avaliação",
          "bullets": [
            "Experiment tracking (MLflow)",
            "Canary/rollback e segurança",
            "Monitoramento de drift e regressões"
          ]
        }
      ]
    },
    "sections": {
      "aboutTitle": "Resumo",
      "aboutSub": "Pragmatismo, produção e qualidade.",
      "skillsTitle": "Competências",
      "skillsSub": "Arquitetura, implementação e entrega.",
      "projectsTitle": "Projetos (seleção)",
      "projectsSub": "Estudos de caso (NDA-friendly) para entender rápido.",
      "experienceTitle": "Experiência & Contribuições",
      "experienceSub": "O que foi entregue, melhorado e estabilizado.",
      "educationTitle": "Formação",
      "educationSub": "IA e engenharia de software com foco em aplicação prática.",
      "contactTitle": "Contato",
      "contactSub": "Melhor: e-mail. Rápido: WhatsApp.",
      "labTitle": "Arquiteturas em ação",
      "labSub": "Um mapa interativo dos blocos que mais uso em produção (RAG, agentes, avaliação e LLMOps).",
      "toolboxTitle": "Toolbox",
      "toolboxSub": "Clique em um item para destacar os projetos que realmente usam aquela peça."
    },
    "about": [
      "Engenheiro de Inteligência Artificial com foco em IA Generativa, Large Language Models (LLMs) e arquiteturas de Retrieval-Augmented Generation (RAG). Experiência em construir pipelines end-to-end e integrar IA em sistemas corporativos (ERP, APIs REST e plataformas Lakehouse).",
      "Atuação prática com fine-tuning (LoRA/PEFT), embeddings, vector databases, agentes multi-step e LLMOps. Trabalho com rigor de engenharia: observabilidade, testes, tratamento de erros e foco em estabilidade e latência.",
      "Parte do portfólio está descrita como estudos de caso anonimizados (NDA-friendly). Posso compartilhar detalhes técnicos adicionais sob demanda."
    ],
    "skills": [
      {
        "group": "GenAI & LLMs",
        "items": [
          "RAG",
          "Agentes multi-step",
          "Prompting estruturado",
          "Guardrails",
          "Avaliação & métricas"
        ]
      },
      {
        "group": "Fine-tuning & NLP",
        "items": [
          "LoRA/PEFT",
          "Hugging Face",
          "Tokenização",
          "Benchmarks",
          "Inference pipelines"
        ]
      },
      {
        "group": "Stacks & Tooling",
        "items": [
          "LangChain",
          "LlamaIndex",
          "FAISS",
          "Chroma",
          "Vector search"
        ]
      },
      {
        "group": "Lakehouse & MLOps",
        "items": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Model Serving",
          "Experiment tracking"
        ]
      },
      {
        "group": "Engenharia",
        "items": [
          "Python avançado",
          "APIs REST",
          "Testes",
          "Profiling",
          "Linux"
        ]
      },
      {
        "group": "Entrega em Produção",
        "items": [
          "Observabilidade",
          "Hardening",
          "Rollbacks",
          "Versionamento",
          "Documentação"
        ]
      }
    ],
    "projects": [
      {
        "title": "ERP/CRM Varejo (NDA) | Estabilidade + Integrações",
        "subtitle": "Integração de módulos críticos, hardening de APIs e qualidade de entrega em produção.",
        "highlights": [
          "Resiliência: reconexão segura, fallback de serviços e redução de falhas intermitentes",
          "Contrato e consistência: validação de rotas, tratamento de erros e auditoria ponta a ponta",
          "Performance: redução de latência perceptível e melhoria de tempo de carga em fluxos críticos"
        ],
        "stack": [
          "Python",
          "REST APIs",
          "Desktop app",
          "Databases",
          "Observability"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Estudo de caso anonimizado (NDA-friendly). Detalhes técnicos sob demanda.",
        "image": "assets/projects/project-erpcrm.svg"
      },
      {
        "title": "Enterprise RAG System",
        "subtitle": "Pipeline completo: ingestão → embeddings → armazenamento vetorial → geração.",
        "highlights": [
          "Ingestão, normalização e chunking com foco em recuperação consistente",
          "Busca semântica com vetores e ajustes de relevância (recall/precision)",
          "Avaliação, guardrails e observabilidade para reduzir respostas não fundamentadas"
        ],
        "stack": [
          "RAG",
          "Embeddings",
          "FAISS/Chroma",
          "LLMOps",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Detalhes de dados e documentos são variáveis por domínio (ajuste rápido por caso).",
        "image": "assets/projects/project-rag.svg",
        "id": "rag",
        "problem": "Busca e resposta em bases documentais grandes tendem a perder precisão sem arquitetura e avaliação.",
        "approach": [
          "Ingestão + chunking estruturado + vetores + reranking (quando necessário)",
          "Métricas e testes de qualidade (offline + online)",
          "Guardrails e observabilidade para reduzir alucinação"
        ],
        "impact": [
          "Respostas mais consistentes e auditáveis",
          "Menos tempo perdido em buscas manuais",
          "Base pronta para operação e evolução contínua"
        ]
      },
      {
        "title": "AI Agent Workflows",
        "subtitle": "Agentes autônomos integrados a ferramentas e APIs externas com segurança.",
        "highlights": [
          "Tool-calling com validação de entrada/saída, limites de execução e segurança",
          "Orquestração multi-step com foco em previsibilidade e rastreabilidade",
          "Testes e avaliação offline para evitar regressões em cenários reais"
        ],
        "stack": [
          "Agents",
          "Tool calling",
          "Guardrails",
          "APIs",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Foco em robustez: execução controlada, logs úteis e falhas previsíveis.",
        "image": "assets/projects/project-agents.svg",
        "id": "agents",
        "problem": "Agentes podem ser poderosos, mas são perigosos sem limites, validação e rastreabilidade.",
        "approach": [
          "Tool-calling com validação de I/O e limites de execução",
          "Orquestração multi-step com logs úteis",
          "Avaliação offline e testes para evitar regressões"
        ],
        "impact": [
          "Execução mais previsível",
          "Falhas tratáveis e rastreáveis",
          "Maior segurança em produção"
        ]
      },
      {
        "title": "Lakehouse LLMOps (Databricks)",
        "subtitle": "Integração de dados + rastreabilidade de modelos em ambiente corporativo.",
        "highlights": [
          "Pipelines com Delta Lake e experiment tracking com MLflow",
          "Serving e monitoramento com métricas de qualidade e rastreabilidade",
          "Integração com sistemas legados e APIs corporativas"
        ],
        "stack": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Serving",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Padrões prontos para monitoramento, versionamento e entrega contínua.",
        "image": "assets/projects/project-lakehouse.svg",
        "id": "lakehouse",
        "problem": "Sem governança, o ciclo de modelos vira \"caixa preta\": difícil rastrear, reproduzir e operar.",
        "approach": [
          "Pipelines Lakehouse (Delta) com rastreabilidade",
          "MLflow para experimentos, versionamento e auditoria",
          "Serving e monitoramento com métricas operacionais"
        ],
        "impact": [
          "Entrega mais controlada e reproduzível",
          "Menos retrabalho em incidentes",
          "Base sólida para evolução de modelos"
        ]
      },
      {
        "id": "finetune",
        "title": "Fine-tuning de Transformers (LoRA/PEFT)",
        "subtitle": "Ajuste fino com foco em qualidade, custo e governança de experimentos.",
        "problem": "Modelos base raramente atendem um domínio específico sem ajuste e avaliação.",
        "approach": [
          "LoRA/PEFT com datasets controlados e rastreáveis",
          "Benchmarks e avaliação (qualitativa + quantitativa)",
          "Pipelines de inferência com atenção a latência e custo"
        ],
        "impact": [
          "Melhor aderência a estilo e domínio",
          "Ciclo de iteração mais rápido e seguro",
          "Base pronta para produção e monitoramento"
        ],
        "highlights": [
          "Experimentos reproduzíveis com tracking",
          "Métricas de qualidade e regressão",
          "Deploy de inferência com foco em confiabilidade"
        ],
        "stack": [
          "Transformers",
          "LoRA/PEFT",
          "Hugging Face",
          "Eval",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Detalhes de datasets/modelos dependem do caso de uso.",
        "image": "assets/projects/project-generic.svg"
      },
      {
        "id": "eval",
        "title": "Avaliação & Observabilidade de LLMs",
        "subtitle": "Métricas, suites de teste e monitoramento para evitar regressões.",
        "problem": "Sem avaliação, sistemas com LLM degradam silenciosamente e ficam imprevisíveis.",
        "approach": [
          "Suites offline (golden set) + checks automatizados",
          "Métricas online (latência, taxa de erro, satisfação)",
          "Dashboards e alertas para falhas e regressões"
        ],
        "impact": [
          "Detecção precoce de regressões",
          "Melhor previsibilidade em produção",
          "Diagnóstico mais rápido em incidentes"
        ],
        "highlights": [
          "Guardrails e validações por rota/caso",
          "Telemetria útil (sem vazamento de dados)",
          "Processo de release mais seguro"
        ],
        "stack": [
          "LLMOps",
          "Observability",
          "Testing",
          "Python",
          "APIs"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Sem números inventados: métricas específicas variam por cliente e contexto.",
        "image": "assets/projects/project-lakehouse.svg"
      }
    ],
    "labels": {
      "repo": "Repo",
      "demo": "Demo",
      "writeup": "Writeup",
      "caseStudy": "Estudo de caso",
      "problem": "Problema",
      "approach": "Abordagem",
      "impact": "Impacto",
      "highlights": "Destaques",
      "stack": "Stack"
    },
    "experience": [
      {
        "when": "Open Source AI",
        "title": "Contribuições em OpenShift AI / InstructLab",
        "org": "Ecossistema Red Hat (conforme CV)",
        "bullets": [
          "Otimização e integração de modelos generativos em ambiente corporativo",
          "Práticas de engenharia: observabilidade, hardening e qualidade de entrega"
        ]
      },
      {
        "when": "NLP / Fine-tuning",
        "title": "Fine-tuning e pipelines (ecossistema Hugging Face)",
        "org": "Projetos e benchmarks de avaliação (conforme CV)",
        "bullets": [
          "Experimentos com LoRA/PEFT e avaliação de qualidade",
          "Pipelines de inferência com foco em desempenho e confiabilidade"
        ]
      },
      {
        "when": "Dados / Automação",
        "title": "Automação de fluxos corporativos + Lakehouse",
        "org": "Volk do Brasil (conforme CV)",
        "bullets": [
          "Automação com Python e integração de dados",
          "Aplicação de IA em plataforma Databricks (Delta/MLflow)"
        ]
      },
      {
        "when": "Embedded / Linux",
        "title": "Linux OEM e sistemas críticos",
        "org": "Perkons & Policorp (conforme CV)",
        "bullets": [
          "Customização de distribuições Linux OEM",
          "Engenharia embarcada e software mission-critical"
        ]
      }
    ],
    "education": [
      {
        "title": "Pós-graduação em Inteligência Artificial",
        "org": "UTFPR",
        "year": "2025"
      },
      {
        "title": "Pós-graduação em Engenharia de Software",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Tecnólogo em Análise e Desenvolvimento de Sistemas",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Pós-graduação em IA Generativa Aplicada",
        "org": "UTFPR",
        "year": "Início Abr/2026",
        "note": "Linha de estudo aplicada em GenAI e LLM systems."
      }
    ],
    "quickLinks": [
      {
        "label": "LinkedIn",
        "href": "https://br.linkedin.com/in/johnny-nordio-533769251",
        "external": true
      },
      {
        "label": "GitHub",
        "href": "https://github.com/Nordio1",
        "external": true
      },
      {
        "label": "WhatsApp",
        "href": "https://wa.me/5541995879232",
        "external": true
      },
      {
        "label": "Email",
        "href": "mailto:mrnordio@icloud.com",
        "external": false
      }
    ],
    "contact": {
      "cardTitle": "Fale comigo",
      "cardSub": "Posso compartilhar writeups técnicos e detalhes dos estudos de caso.",
      "phoneCta": "WhatsApp",
      "linkedinCta": "LinkedIn",
      "quickTitle": "Links rápidos",
      "quickNote": "Links úteis para contato e portfólio.",
      "privacy": "Página pública. Sem scripts de tracking."
    },
    "footer": {
      "backTop": "Voltar ao topo"
    },
    "lab": {
      "legend": [
        {
          "label": "RAG",
          "hint": "Recuperação + geração"
        },
        {
          "label": "Agentes",
          "hint": "Tool-calling multi-step"
        },
        {
          "label": "Avaliação",
          "hint": "Qualidade e regressão"
        },
        {
          "label": "LLMOps",
          "hint": "Deploy e monitoramento"
        }
      ],
      "nodes": [
        {
          "id": "sources",
          "label": "Fontes",
          "x": 16,
          "y": 20,
          "title": "Fontes e ingestão",
          "body": "Ponto de partida: documentos, tabelas, eventos e dados operacionais. A chave é consistência e rastreabilidade.",
          "bullets": [
            "Normalização e deduplicação",
            "Controle de versões de dados",
            "Trilha de auditoria (o que entrou e quando)"
          ],
          "links": [
            "chunking"
          ]
        },
        {
          "id": "chunking",
          "label": "Chunking",
          "x": 38,
          "y": 30,
          "title": "Chunking e indexação",
          "body": "Separar conteúdo em partes recuperáveis aumenta a qualidade do RAG. Estratégias mudam por domínio.",
          "bullets": [
            "Chunking por estrutura (título/seção/tabela)",
            "Metadados para filtros",
            "Testes de recall/precision"
          ],
          "links": [
            "vectors",
            "eval"
          ]
        },
        {
          "id": "vectors",
          "label": "Vetores",
          "x": 60,
          "y": 18,
          "title": "Embeddings + vector store",
          "body": "Embeddings traduzem texto em vetores. O index precisa ser rápido, consistente e observável.",
          "bullets": [
            "FAISS/Chroma e filtros",
            "Cache e batching",
            "Reranking quando necessário"
          ],
          "links": [
            "rag"
          ]
        },
        {
          "id": "rag",
          "label": "RAG",
          "x": 72,
          "y": 42,
          "title": "RAG (retrieval + geração)",
          "body": "Resposta com base em evidências recuperadas. O objetivo é reduzir alucinação e aumentar precisão.",
          "bullets": [
            "Contexto citado/ancorado",
            "Prompts estruturados",
            "Fallbacks e limites"
          ],
          "links": [
            "guardrails",
            "eval"
          ]
        },
        {
          "id": "agents",
          "label": "Agentes",
          "x": 22,
          "y": 58,
          "title": "Agentes com ferramentas",
          "body": "Agentes chamam ferramentas/APIs. O segredo é previsibilidade: limites, validação e logs úteis.",
          "bullets": [
            "Tool-calling com validação",
            "Execução multi-step controlada",
            "Erros previsíveis e rastreáveis"
          ],
          "links": [
            "guardrails",
            "ops"
          ]
        },
        {
          "id": "guardrails",
          "label": "Guardrails",
          "x": 52,
          "y": 60,
          "title": "Guardrails e segurança",
          "body": "Regras para evitar saídas perigosas e reduzir comportamento inesperado em produção.",
          "bullets": [
            "Validação de entrada/saída",
            "Políticas de dados e PII",
            "Rate limits e timeouts"
          ],
          "links": [
            "eval"
          ]
        },
        {
          "id": "eval",
          "label": "Avaliação",
          "x": 78,
          "y": 70,
          "title": "Avaliação contínua",
          "body": "Sem avaliação, sistema degrada. O foco é criar testes e métricas que detectem regressão cedo.",
          "bullets": [
            "Suites offline (golden set)",
            "Métricas online (qualidade/latência)",
            "Observabilidade e alertas"
          ],
          "links": [
            "ops"
          ]
        },
        {
          "id": "ops",
          "label": "LLMOps",
          "x": 90,
          "y": 56,
          "title": "LLMOps (deploy e monitoramento)",
          "body": "Entrega com controle: versionamento, canary, rollback e monitoramento por custo/latência/qualidade.",
          "bullets": [
            "MLflow / tracking",
            "Deploy seguro (canary/rollback)",
            "Monitoramento + auditoria"
          ],
          "links": []
        }
      ]
    },
    "toolbox": {
      "clear": "Limpar",
      "help": "Dica: Shift+clique para selecionar mais de um item.",
      "countLabel": "projetos"
    },
    "cmdk": {
      "open": "Comandos",
      "title": "Comandos",
      "placeholder": "Buscar seções, projetos e links...",
      "hint": "Use ↑/↓ e Enter. Pressione Ctrl+K para abrir de qualquer lugar.",
      "sectionHint": "Ir para seção",
      "actionHint": "Ação rápida",
      "toggleTheme": "Alternar tema",
      "email": "E-mail",
      "whatsapp": "WhatsApp",
      "kinds": {
        "section": "Seção",
        "project": "Projeto",
        "link": "Link",
        "action": "Ação"
      }
    }
  },
  "en": {
    "meta": {
      "title": "Johnny Nordio | AI Engineer",
      "description": "Artificial Intelligence Engineer focused on Generative AI, LLMs, RAG, agents, and LLMOps.",
      "ogDescription": "Generative AI • LLMs • RAG • Agents • LLMOps"
    },
    "profile": {
      "email": "mrnordio@icloud.com",
      "whatsapp": "https://wa.me/5541995879232",
      "github": "https://github.com/Nordio1",
      "linkedin": "https://br.linkedin.com/in/johnny-nordio-533769251"
    },
    "nav": {
      "about": "Summary",
      "skills": "Skills",
      "projects": "Projects",
      "experience": "Experience",
      "education": "Education",
      "contact": "Contact",
      "lab": "Systems",
      "toolbox": "Toolbox"
    },
    "theme": {
      "toDark": "Dark mode",
      "toLight": "Light mode",
      "aria": "Toggle theme"
    },
    "hero": {
      "eyebrow": "AI ENGINEER",
      "name": "Johnny Nordio",
      "tagline": "AI ENGINEER | GENERATIVE AI SPECIALIST | LLM SYSTEMS ARCHITECT",
      "location": "Curitiba, Brazil | Open to Global Remote Roles",
      "ctaPrimary": "Email me",
      "ctaSecondary": "View projects",
      "ctaLinkedin": "LinkedIn",
      "note": "Some work is anonymized (NDA-friendly). Details available on request.",
      "panelTitle": "Focus",
      "panelTitle2": "What I build",
      "focus": [
        "LLMs",
        "RAG",
        "Agents",
        "LLMOps",
        "Fine-tuning (LoRA/PEFT)",
        "APIs & Integrations"
      ],
      "build": [
        "End-to-end RAG pipelines (ingestion → embeddings → vector store → generation)",
        "LLM evaluation, monitoring, and guardrails",
        "AI integration into enterprise ERPs and REST APIs",
        "Performance, stability, and observability improvements"
      ],
      "panelTitle3": "Pipelines",
      "pipelineHint": "Click to explore",
      "pipeline": [
        {
          "id": "ingest",
          "title": "Ingestion",
          "desc": "Docs, data, logs",
          "bullets": [
            "Ingestion with normalization + deduplication",
            "Chunking strategies per data type",
            "Source versioning and audit trail"
          ]
        },
        {
          "id": "embed",
          "title": "Embeddings",
          "desc": "Semantic representations",
          "bullets": [
            "Model selection by domain/cost/latency",
            "Batching and caching to reduce cost",
            "Continuous recall/precision evaluation"
          ]
        },
        {
          "id": "vector",
          "title": "Vector search",
          "desc": "Retrieval with relevance",
          "bullets": [
            "Vector DB (FAISS/Chroma) + filters",
            "Reranking when needed",
            "Query/hit observability"
          ]
        },
        {
          "id": "gen",
          "title": "Generation",
          "desc": "LLM with guardrails",
          "bullets": [
            "Structured prompting + context windows",
            "Output validation and guardrails",
            "Quality metrics (offline + online)"
          ]
        },
        {
          "id": "ops",
          "title": "LLMOps",
          "desc": "Deploy, monitoring, evaluation",
          "bullets": [
            "Experiment tracking (MLflow)",
            "Canary/rollback and security",
            "Drift monitoring and regressions"
          ]
        }
      ]
    },
    "sections": {
      "aboutTitle": "Executive Summary",
      "aboutSub": "Pragmatic, production-focused, quality-driven.",
      "skillsTitle": "Strategic Expertise",
      "skillsSub": "Architecture, implementation, and delivery.",
      "projectsTitle": "Selected Projects",
      "projectsSub": "NDA-friendly case studies you can scan in 60 seconds.",
      "experienceTitle": "Experience & Contributions",
      "experienceSub": "What shipped, what improved, and what stabilized.",
      "educationTitle": "Education",
      "educationSub": "AI and software engineering with a hands-on bias.",
      "contactTitle": "Contact",
      "contactSub": "Best: email. Fast: WhatsApp.",
      "labTitle": "Architectures in action",
      "labSub": "An interactive map of the building blocks I ship in production (RAG, agents, evaluation, LLMOps).",
      "toolboxTitle": "Toolbox",
      "toolboxSub": "Click a tag to highlight projects that actually use it."
    },
    "about": [
      "Artificial Intelligence Engineer focused on Generative AI, Large Language Models (LLMs), and Retrieval-Augmented Generation (RAG) architectures. Experienced in building end-to-end pipelines and integrating AI into enterprise systems (ERP, REST APIs, and Lakehouse platforms).",
      "Hands-on with fine-tuning (LoRA/PEFT), embeddings, vector databases, multi-step agents, and LLMOps. Strong engineering rigor: observability, testing, error handling, and a relentless focus on stability and latency.",
      "Some portfolio items are described as anonymized case studies (NDA-friendly). I can share deeper technical details on request."
    ],
    "skills": [
      {
        "group": "GenAI & LLMs",
        "items": [
          "RAG",
          "Multi-step agents",
          "Structured prompting",
          "Guardrails",
          "Evaluation & metrics"
        ]
      },
      {
        "group": "Fine-tuning & NLP",
        "items": [
          "LoRA/PEFT",
          "Hugging Face",
          "Tokenization",
          "Benchmarks",
          "Inference pipelines"
        ]
      },
      {
        "group": "Stacks & Tooling",
        "items": [
          "LangChain",
          "LlamaIndex",
          "FAISS",
          "Chroma",
          "Vector search"
        ]
      },
      {
        "group": "Lakehouse & MLOps",
        "items": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Model Serving",
          "Experiment tracking"
        ]
      },
      {
        "group": "Engineering",
        "items": [
          "Advanced Python",
          "REST APIs",
          "Testing",
          "Profiling",
          "Linux"
        ]
      },
      {
        "group": "Production Delivery",
        "items": [
          "Observability",
          "Hardening",
          "Rollbacks",
          "Versioning",
          "Docs"
        ]
      }
    ],
    "projects": [
      {
        "title": "Retail ERP/CRM (NDA) | Stability + Integrations",
        "subtitle": "Critical module integration, API hardening, and production-grade delivery.",
        "highlights": [
          "Resilience: safe reconnection, service fallback, and fewer intermittent failures",
          "Consistency: route validation, error handling, and end-to-end auditing",
          "Performance: lower perceived latency and faster critical flows"
        ],
        "stack": [
          "Python",
          "REST APIs",
          "Desktop app",
          "Databases",
          "Observability"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Anonymized case study (NDA-friendly). Deeper technical details on request.",
        "image": "assets/projects/project-erpcrm.svg",
        "id": "erp-crm",
        "problem": "Retail operations require stability, traceability, and integrations without production surprises.",
        "approach": [
          "API hardening, error handling, and observability",
          "Fiscal snapshot + end-to-end audit trail",
          "Guided critical flows and human-friendly UX"
        ],
        "impact": [
          "Fewer intermittent failures and more predictable behavior",
          "Consistent data (ERP ? API ? CRM) with reliable persistence",
          "Operational delivery designed for support and maintenance"
        ]
      },
      {
        "title": "Enterprise RAG System",
        "subtitle": "Full pipeline: ingestion → embeddings → vector store → generation.",
        "highlights": [
          "Ingestion, normalization, and chunking designed for consistent retrieval",
          "Semantic search with vector stores and relevance tuning (recall/precision)",
          "Evaluation, guardrails, and observability to reduce ungrounded answers"
        ],
        "stack": [
          "RAG",
          "Embeddings",
          "FAISS/Chroma",
          "LLMOps",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Data sources and documents vary by domain (fast adaptation per use case).",
        "image": "assets/projects/project-rag.svg",
        "id": "rag",
        "problem": "Answering over large document bases tends to lose accuracy without architecture and evaluation.",
        "approach": [
          "Structured ingestion + chunking + vectors + reranking when needed",
          "Quality metrics and evaluation (offline + online)",
          "Guardrails and observability to reduce hallucinations"
        ],
        "impact": [
          "More consistent, auditable answers",
          "Less time spent on manual search",
          "Production-ready foundation for continuous improvement"
        ]
      },
      {
        "title": "AI Agent Workflows",
        "subtitle": "Autonomous agents integrated with tools and external APIs, safely.",
        "highlights": [
          "Tool-calling with strict I/O validation, execution limits, and safety",
          "Multi-step orchestration designed for predictability and traceability",
          "Offline evaluation and regression tests for real-world scenarios"
        ],
        "stack": [
          "Agents",
          "Tooling",
          "Guardrails",
          "APIs",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Robustness first: controlled execution, useful logs, predictable failures.",
        "image": "assets/projects/project-agents.svg",
        "id": "agents",
        "problem": "Agents are powerful but risky without limits, validation, and traceability.",
        "approach": [
          "Tool calling with strict I/O validation and execution limits",
          "Multi-step orchestration with useful logs",
          "Offline evaluation and regression tests"
        ],
        "impact": [
          "More predictable execution",
          "Traceable failures",
          "Better production safety"
        ]
      },
      {
        "title": "Lakehouse LLMOps (Databricks)",
        "subtitle": "Data integration + model traceability in enterprise environments.",
        "highlights": [
          "Delta Lake pipelines + MLflow experiment tracking",
          "Serving and monitoring with quality metrics and traceability",
          "Integration with legacy systems and enterprise APIs"
        ],
        "stack": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Serving",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Patterns ready for monitoring, versioning, and continuous delivery.",
        "image": "assets/projects/project-lakehouse.svg",
        "id": "lakehouse",
        "problem": "Without governance, the model lifecycle becomes a black box: hard to trace, reproduce, and operate.",
        "approach": [
          "Lakehouse pipelines (Delta) with traceability",
          "MLflow for experiments, versioning, and auditability",
          "Serving + monitoring with operational metrics"
        ],
        "impact": [
          "More controlled, reproducible delivery",
          "Less rework during incidents",
          "Solid base for model iteration"
        ]
      },
      {
        "id": "finetune",
        "title": "Transformer Fine-Tuning (LoRA/PEFT)",
        "subtitle": "Fine-tuning focused on quality, cost, and experiment governance.",
        "problem": "Base models rarely meet a specific domain without adaptation and evaluation.",
        "approach": [
          "LoRA/PEFT with controlled, traceable datasets",
          "Benchmarks and evaluation (qualitative + quantitative)",
          "Inference pipelines with latency/cost awareness"
        ],
        "impact": [
          "Better domain fit and style alignment",
          "Faster, safer iteration cycles",
          "Production-ready foundation with monitoring"
        ],
        "highlights": [
          "Reproducible experiments with tracking",
          "Quality and regression metrics",
          "Reliable inference delivery"
        ],
        "stack": [
          "Transformers",
          "LoRA/PEFT",
          "Hugging Face",
          "Eval",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Model/dataset details vary by use case.",
        "image": "assets/projects/project-generic.svg"
      },
      {
        "id": "eval",
        "title": "LLM Evaluation & Observability",
        "subtitle": "Metrics, test suites, and monitoring to prevent regressions.",
        "problem": "Without evaluation, LLM systems degrade silently and become unpredictable.",
        "approach": [
          "Offline suites (golden set) + automated checks",
          "Online metrics (latency, error rate, satisfaction)",
          "Dashboards and alerts for failures/regressions"
        ],
        "impact": [
          "Earlier regression detection",
          "Better production predictability",
          "Faster incident diagnosis"
        ],
        "highlights": [
          "Guardrails and validations per route/case",
          "Useful telemetry (without leaking data)",
          "Safer release process"
        ],
        "stack": [
          "LLMOps",
          "Observability",
          "Testing",
          "Python",
          "APIs"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "No fabricated numbers: metrics are context-dependent.",
        "image": "assets/projects/project-lakehouse.svg"
      }
    ],
    "labels": {
      "repo": "Repo",
      "demo": "Demo",
      "writeup": "Writeup",
      "caseStudy": "Case study",
      "problem": "Problem",
      "approach": "Approach",
      "impact": "Impact",
      "highlights": "Highlights",
      "stack": "Stack"
    },
    "experience": [
      {
        "when": "Open Source AI",
        "title": "OpenShift AI / InstructLab contributions",
        "org": "Red Hat ecosystem (per CV)",
        "bullets": [
          "Contributions and improvements focused on GenAI workflows for enterprise use",
          "Hardening: error handling, useful logs, validations, predictable behavior",
          "Performance/latency improvements and fewer intermittent pipeline failures",
          "Engineering discipline: tests, release notes, sustainable maintenance"
        ]
      },
      {
        "when": "NLP / Fine-tuning",
        "title": "Fine-tuning and inference pipelines (Hugging Face ecosystem)",
        "org": "Projects and evaluation benchmarks (per CV)",
        "bullets": [
          "LoRA/PEFT experiments and quality evaluation",
          "Inference pipelines with performance and reliability focus"
        ]
      },
      {
        "when": "Data / Automation",
        "title": "Enterprise workflow automation + Lakehouse",
        "org": "Volk do Brasil (per CV)",
        "bullets": [
          "Python automation and data integration across systems",
          "Lakehouse pipelines (Delta) with traceability and data quality",
          "MLflow for experiment tracking/versioning and governance",
          "Integration with enterprise APIs and legacy systems"
        ]
      },
      {
        "when": "Embedded / Linux",
        "title": "Linux OEM and mission-critical systems",
        "org": "Perkons & Policorp (per CV)",
        "bullets": [
          "Linux OEM distribution customization and build/deploy processes",
          "Embedded engineering and hardware integrations when applicable",
          "Stability focus: diagnosis, logs, safe fixes",
          "Tooling and processes for critical software maintenance"
        ]
      }
    ],
    "education": [
      {
        "title": "Postgraduate Degree in Artificial Intelligence",
        "org": "UTFPR",
        "year": "2025"
      },
      {
        "title": "Postgraduate Degree in Software Engineering",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Technologist Degree in Systems Analysis and Development",
        "org": "Universidade Positivo",
        "year": ""
      },
      {
        "title": "Postgraduate Degree in Applied Generative AI",
        "org": "UTFPR",
        "year": "Starting Apr/2026",
        "note": "Applied track for GenAI and LLM systems."
      }
    ],
    "quickLinks": [
      {
        "label": "LinkedIn",
        "href": "https://br.linkedin.com/in/johnny-nordio-533769251",
        "external": true
      },
      {
        "label": "GitHub",
        "href": "https://github.com/Nordio1",
        "external": true
      },
      {
        "label": "WhatsApp",
        "href": "https://wa.me/5541995879232",
        "external": true
      },
      {
        "label": "Email",
        "href": "mailto:mrnordio@icloud.com",
        "external": false
      }
    ],
    "contact": {
      "cardTitle": "Get in touch",
      "cardSub": "Happy to share deeper technical writeups and case study details.",
      "phoneCta": "WhatsApp",
      "linkedinCta": "LinkedIn",
      "quickTitle": "Quick links",
      "quickNote": "Useful links for contact and work.",
      "privacy": "Public page. No tracking scripts."
    },
    "footer": {
      "backTop": "Back to top"
    },
    "lab": {
      "legend": [
        {
          "label": "RAG",
          "hint": "Retrieval + generation"
        },
        {
          "label": "Agents",
          "hint": "Multi-step tool calling"
        },
        {
          "label": "Evaluation",
          "hint": "Quality and regressions"
        },
        {
          "label": "LLMOps",
          "hint": "Deploy and monitoring"
        }
      ],
      "nodes": [
        {
          "id": "sources",
          "label": "Sources",
          "x": 16,
          "y": 20,
          "title": "Sources and ingestion",
          "body": "Starting point: documents, tables, events, operational data. The key is consistency and traceability.",
          "bullets": [
            "Normalization and deduplication",
            "Data versioning",
            "Audit trail (what/when)"
          ],
          "links": [
            "chunking"
          ]
        },
        {
          "id": "chunking",
          "label": "Chunking",
          "x": 38,
          "y": 30,
          "title": "Chunking and indexing",
          "body": "Splitting content into retrievable units improves RAG quality. Strategies vary by domain.",
          "bullets": [
            "Structure-aware chunking",
            "Metadata for filters",
            "Recall/precision testing"
          ],
          "links": [
            "vectors",
            "eval"
          ]
        },
        {
          "id": "vectors",
          "label": "Vectors",
          "x": 60,
          "y": 18,
          "title": "Embeddings + vector store",
          "body": "Embeddings turn text into vectors. Indexes must be fast, consistent, and observable.",
          "bullets": [
            "FAISS/Chroma and filters",
            "Caching and batching",
            "Reranking when needed"
          ],
          "links": [
            "rag"
          ]
        },
        {
          "id": "rag",
          "label": "RAG",
          "x": 72,
          "y": 42,
          "title": "RAG (retrieval + generation)",
          "body": "Evidence-grounded answers. Goal: reduce hallucination and increase accuracy.",
          "bullets": [
            "Anchored context",
            "Structured prompts",
            "Fallbacks and limits"
          ],
          "links": [
            "guardrails",
            "eval"
          ]
        },
        {
          "id": "agents",
          "label": "Agents",
          "x": 22,
          "y": 58,
          "title": "Tool-enabled agents",
          "body": "Agents call tools/APIs. The secret is predictability: limits, validation, and useful logs.",
          "bullets": [
            "Tool calling with validation",
            "Controlled multi-step execution",
            "Predictable failures"
          ],
          "links": [
            "guardrails",
            "ops"
          ]
        },
        {
          "id": "guardrails",
          "label": "Guardrails",
          "x": 52,
          "y": 60,
          "title": "Guardrails and safety",
          "body": "Policies to reduce unsafe outputs and unexpected behavior in production.",
          "bullets": [
            "I/O validation",
            "Data/PII policies",
            "Rate limits and timeouts"
          ],
          "links": [
            "eval"
          ]
        },
        {
          "id": "eval",
          "label": "Evaluation",
          "x": 78,
          "y": 70,
          "title": "Continuous evaluation",
          "body": "Without evaluation, systems degrade. Focus: tests and metrics that catch regressions early.",
          "bullets": [
            "Offline suites (golden set)",
            "Online metrics (quality/latency)",
            "Observability and alerts"
          ],
          "links": [
            "ops"
          ]
        },
        {
          "id": "ops",
          "label": "LLMOps",
          "x": 90,
          "y": 56,
          "title": "LLMOps (deploy and monitoring)",
          "body": "Delivery with control: versioning, canary, rollback and monitoring for cost/latency/quality.",
          "bullets": [
            "MLflow / tracking",
            "Safe deploy (canary/rollback)",
            "Monitoring + audit trail"
          ],
          "links": []
        }
      ]
    },
    "toolbox": {
      "clear": "Clear",
      "help": "Tip: Shift+click to multi-select.",
      "countLabel": "projects"
    },
    "cmdk": {
      "open": "Cmd+K",
      "title": "Command palette",
      "placeholder": "Search sections, projects and links...",
      "hint": "Use ↑/↓ and Enter. Press Ctrl+K (or Cmd+K) from anywhere.",
      "sectionHint": "Jump to section",
      "actionHint": "Quick action",
      "toggleTheme": "Toggle theme",
      "email": "Email",
      "whatsapp": "WhatsApp",
      "kinds": {
        "section": "Section",
        "project": "Project",
        "link": "Link",
        "action": "Action"
      }
    }
  }
}
