{
  "pt": {
    "meta": {
      "title": "Johnny Nordio | Engenheiro de IA",
      "description": "Engenheiro de Inteligência Artificial focado em IA Generativa, LLMs, RAG, agentes e LLMOps.",
      "ogDescription": "IA Generativa • LLMs • RAG • Agentes • LLMOps"
    },
    "profile": {
      "email": "mrnordio@icloud.com",
      "whatsapp": "https://wa.me/5541995879232",
      "github": "https://github.com/Nordio1",
      "linkedin": "https://br.linkedin.com/in/johnny-nordio-533769251"
    },
    "nav": {
      "about": "Resumo",
      "skills": "Competências",
      "projects": "Projetos",
      "experience": "Experiência",
      "education": "Formação",
      "contact": "Contato",
      "lab": "Arquiteturas",
      "toolbox": "Toolbox"
    },
    "theme": {
      "toDark": "Modo escuro",
      "toLight": "Modo claro",
      "aria": "Alternar tema"
    },
    "hero": {
      "eyebrow": "AI ENGINEER",
      "name": "Johnny Nordio",
      "tagline": "AI ENGINEER | GENERATIVE AI SPECIALIST | LLM SYSTEMS ARCHITECT",
      "location": "Curitiba - PR | Disponível para remoto internacional",
      "ctaPrimary": "Falar por e-mail",
      "ctaSecondary": "Ver projetos",
      "ctaLinkedin": "LinkedIn",
      "note": "Parte do trabalho está anonimizada (NDA). Detalhes sob demanda.",
      "panelTitle": "Foco",
      "panelTitle2": "O que eu construo",
      "focus": [
        "LLMs",
        "RAG",
        "Agentes",
        "LLMOps",
        "Fine-tuning (LoRA/PEFT)",
        "APIs & Integrações"
      ],
      "build": [
        "Pipelines de RAG end-to-end (ingestão → embeddings → vetores → geração)",
        "Avaliação, monitoramento e guardrails para LLMs",
        "Integração de IA em ERPs e APIs REST",
        "Otimização de desempenho, estabilidade e observabilidade"
      ],
      "panelTitle3": "Pipelines",
      "pipelineHint": "Clique para explorar",
      "pipeline": [
        {
          "id": "ingest",
          "title": "Ingestão",
          "desc": "Documentos, dados e logs",
          "bullets": [
            "Ingestão com normalização + deduplicação",
            "Chunking com estratégia por tipo de dado",
            "Versionamento de fontes e trilha de auditoria"
          ]
        },
        {
          "id": "embed",
          "title": "Embeddings",
          "desc": "Representação semântica",
          "bullets": [
            "Seleção de modelo por domínio/custo/latência",
            "Batching e cache para reduzir custo",
            "Avaliação contínua de recall/precision"
          ]
        },
        {
          "id": "vector",
          "title": "Busca vetorial",
          "desc": "Recuperação com relevância",
          "bullets": [
            "Vector DB (FAISS/Chroma) + filtros",
            "Reranking quando necessário",
            "Observabilidade de consultas e hits"
          ]
        },
        {
          "id": "gen",
          "title": "Geração",
          "desc": "LLM com guardrails",
          "bullets": [
            "Prompts estruturados + context windows",
            "Guardrails e validação de saída",
            "Métricas de qualidade (offline + online)"
          ]
        },
        {
          "id": "ops",
          "title": "LLMOps",
          "desc": "Deploy, monitoramento, avaliação",
          "bullets": [
            "Experiment tracking (MLflow)",
            "Canary/rollback e segurança",
            "Monitoramento de drift e regressões"
          ]
        }
      ],
      "featureTitle": "Case studies em destaque",
      "featureSub": "Clique para abrir um deep-dive rápido (problema, abordagem, impacto).",
      "featureHint": "Dica: Ctrl/Cmd+K para buscar seções, projetos e links.",
      "featuredProjectIds": [
        "erp-crm",
        "rag",
        "agents"
      ]
    },
    "sections": {
      "aboutTitle": "Resumo",
      "aboutSub": "Pragmatismo, produção e qualidade.",
      "skillsTitle": "Competências",
      "skillsSub": "Arquitetura, implementação e entrega.",
      "projectsTitle": "Projetos (seleção)",
      "projectsSub": "Estudos de caso (NDA-friendly) para entender rápido.",
      "experienceTitle": "Experiência & Contribuições",
      "experienceSub": "O que foi entregue, melhorado e estabilizado.",
      "educationTitle": "Formação",
      "educationSub": "IA e engenharia de software com foco em aplicação prática.",
      "certsTitle": "Certificações",
      "certsSub": "Credenciais e cursos relevantes (GenAI, cloud e engenharia).",
      "contactTitle": "Contato",
      "contactSub": "Melhor: e-mail. Rápido: WhatsApp.",
      "labTitle": "Arquiteturas em ação",
      "labSub": "Um mapa interativo dos blocos que mais uso em produção (RAG, agentes, avaliação e LLMOps).",
      "toolboxTitle": "Toolbox",
      "toolboxSub": "Clique em um item para destacar os projetos que realmente usam aquela peça."
    },
    "about": [
      "Engenheiro de Inteligência Artificial com foco em IA Generativa, Large Language Models (LLMs) e arquiteturas de Retrieval-Augmented Generation (RAG). Experiência em construir pipelines end-to-end e integrar IA em sistemas corporativos (ERP, APIs REST e plataformas Lakehouse).",
      "Atuação prática com fine-tuning (LoRA/PEFT), embeddings, vector databases, agentes multi-step e LLMOps. Trabalho com rigor de engenharia: observabilidade, testes, tratamento de erros e foco em estabilidade e latência.",
      "Parte do portfólio está descrita como estudos de caso anonimizados (NDA-friendly). Posso compartilhar detalhes técnicos adicionais sob demanda."
    ],
    "skills": [
      {
        "group": "GenAI & LLMs",
        "items": [
          "RAG",
          "Agentes multi-step",
          "Prompting estruturado",
          "Guardrails",
          "Avaliação & métricas"
        ]
      },
      {
        "group": "Fine-tuning & NLP",
        "items": [
          "LoRA/PEFT",
          "Hugging Face",
          "Tokenização",
          "Benchmarks",
          "Inference pipelines"
        ]
      },
      {
        "group": "Stacks & Tooling",
        "items": [
          "LangChain",
          "LlamaIndex",
          "FAISS",
          "Chroma",
          "Vector search"
        ]
      },
      {
        "group": "Lakehouse & MLOps",
        "items": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Model Serving",
          "Experiment tracking"
        ]
      },
      {
        "group": "Engenharia",
        "items": [
          "Python avançado",
          "APIs REST",
          "Testes",
          "Profiling",
          "Linux"
        ]
      },
      {
        "group": "Entrega em Produção",
        "items": [
          "Observabilidade",
          "Hardening",
          "Rollbacks",
          "Versionamento",
          "Documentação"
        ]
      }
    ],
    "projects": [
      {
        "title": "ERP/CRM Varejo (NDA) | Estabilidade + Integrações",
        "subtitle": "Resiliência, trilha de auditoria e integrações críticas em um ERP/CRM desktop (NDA).",
        "highlights": [
          "Hardening de APIs: validação, erros tratados, observabilidade e compatibilidade retroativa",
          "Paridade ERP<->CRM: diagnóstico por rota, contratos e roundtrip de dados consistente",
          "UX guiada para fluxos críticos (venda/pagamento) com auditoria ponta a ponta"
        ],
        "stack": [
          "Python",
          "REST APIs",
          "Desktop app",
          "Databases",
          "Observability"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Estudo de caso anonimizado (NDA-friendly). Detalhes técnicos sob demanda.",
        "image": "assets/projects/project-erpcrm.svg",
        "id": "erp-crm",
        "problem": "Operação de varejo não tolera instabilidade: uma desconexão em venda/estoque/fiscal vira retrabalho, inconsistência e suporte caro.",
        "approach": [
          "Contratos canônicos de rotas + testes automatizados para capturar regressões antes do release",
          "Camada de rede resiliente (timeout/backoff/fallback) com retries idempotentes para evitar duplicidade de gravações",
          "Persistência consistente: configurações e estados críticos sempre no banco (sem \"estado em memória\") + validações de unicidade",
          "Auditoria como trilha de verdade: registrar quem fez o quê e quando, com mensagens operacionais e sem vazar segredos",
          "Profiling + otimização de queries e carregamento lazy para reduzir \"travadas\" em abas pesadas"
        ],
        "impact": [
          "Comportamento previsível em produção: menos falhas intermitentes e reconexão segura",
          "Integridade de dados: ERP -> API -> CRM sem perda de campos e com rastreabilidade",
          "Operação mais simples: diagnóstico mais rápido e releases mais seguros"
        ]
      },
      {
        "title": "Enterprise RAG System",
        "subtitle": "Pipeline completo: ingestão → embeddings → armazenamento vetorial → geração.",
        "highlights": [
          "Ingestão versionada: dedup + metadados + chunking por estrutura",
          "Recuperação híbrida: filtros + vetores + reranking, com cache e observabilidade",
          "Qualidade em produção: suites de avaliação + guardrails + respostas com evidências"
        ],
        "stack": [
          "RAG",
          "Embeddings",
          "FAISS/Chroma",
          "LLMOps",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Detalhes de dados e documentos são variáveis por domínio (ajuste rápido por caso).",
        "image": "assets/projects/project-rag.svg",
        "id": "rag",
        "problem": "RAG \"naive\" quebra em produção: documentos mudam, a recuperação traz ruído e ninguém mede qualidade, gerando respostas erradas com confiança.",
        "approach": [
          "Pipeline de ingestão incremental com versionamento de fontes, deduplicação e metadados",
          "Chunking adaptativo por tipo de documento (título/seção/tabela) + normalização",
          "Recuperação com vetores + filtros, reranking e tuning por recall/precision",
          "Avaliação contínua (golden set) + gates de regressão antes de mudanças de prompt/modelo",
          "Guardrails: schemas, redaction de PII, citações obrigatórias e controles de custo/latência"
        ],
        "impact": [
          "Respostas mais confiáveis e auditáveis (com evidências/citações)",
          "Menos risco de alucinação e regressões silenciosas",
          "Loop de melhoria contínua: medir -> ajustar -> revalidar"
        ]
      },
      {
        "title": "AI Agent Workflows",
        "subtitle": "Agentes autônomos integrados a ferramentas e APIs externas com segurança.",
        "highlights": [
          "Tool-calling seguro: schemas, allowlist, budgets/timeouts e validação de I/O",
          "Orquestração determinística: estado explícito, logs úteis e replay de execuções",
          "Avaliação por cenários + regressão: agentes tratáveis como software"
        ],
        "stack": [
          "Agents",
          "Tool calling",
          "Guardrails",
          "APIs",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Foco em robustez: execução controlada, logs úteis e falhas previsíveis.",
        "image": "assets/projects/project-agents.svg",
        "id": "agents",
        "problem": "Agentes que chamam ferramentas têm efeitos colaterais reais; sem limites, ficam imprevisíveis, inseguros e difíceis de depurar.",
        "approach": [
          "Design de ferramentas com contratos (schemas) e validação rigorosa de inputs/outputs",
          "Políticas de segurança: allowlists, budgets/timeouts, rate limits e aprovação humana para ações sensíveis",
          "Orquestração multi-step com estado explícito, idempotência e logs por etapa",
          "Test harness com cenários reais + replay para depuração e regressão",
          "Observabilidade: tracing por step, custo/latência e erros acionáveis"
        ],
        "impact": [
          "Agentes previsíveis, testáveis e fáceis de operar",
          "Menos risco operacional em integrações com sistemas externos",
          "Time-to-market mais rápido para novos workflows e ferramentas"
        ]
      },
      {
        "title": "Lakehouse LLMOps (Databricks)",
        "subtitle": "Integração de dados + rastreabilidade de modelos em ambiente corporativo.",
        "highlights": [
          "Lineage e reprodutibilidade: Delta Lake + checks de qualidade de dados",
          "Governança de modelos: MLflow tracking/registry + deploy canary/rollback",
          "Operação: métricas online + alertas (sem números inventados)"
        ],
        "stack": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Serving",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Padrões prontos para monitoramento, versionamento e entrega contínua.",
        "image": "assets/projects/project-lakehouse.svg",
        "id": "lakehouse",
        "problem": "Sem governança, o ciclo de dados/modelos vira caixa-preta: difícil reproduzir, auditar e operar sob pressão.",
        "approach": [
          "Pipelines Lakehouse com versionamento, validações e trilha de lineage",
          "MLflow para tracking/registro/versionamento, com artefatos reproduzíveis",
          "Deploy com canary + rollback e monitoramento por custo/latência/qualidade",
          "Integração com APIs/sistemas legados e controles de acesso",
          "Operação contínua: alertas, playbooks e rotinas de validação"
        ],
        "impact": [
          "Entrega controlada e auditável do ciclo inteiro",
          "Resposta mais rápida a incidentes e regressões",
          "Base pronta para escalar para múltiplos domínios/equipes"
        ]
      },
      {
        "id": "finetune",
        "title": "Fine-tuning de Transformers (LoRA/PEFT)",
        "subtitle": "Ajuste fino com foco em qualidade, custo e governança de experimentos.",
        "problem": "Modelos base não refletem linguagem de domínio; fine-tuning sem avaliação vira overfitting e regressões difíceis de perceber.",
        "approach": [
          "Curadoria/limpeza/segmentação de datasets e instruções por objetivo",
          "LoRA/PEFT com experimentos reproduzíveis + versionamento de dados e configs",
          "Benchmarks e avaliação qualitativa+quantitativa, com baseline e ablações",
          "Pipelines de inferência com atenção a latência/custo + monitoração",
          "Gates de release e rollback quando degrada"
        ],
        "impact": [
          "Modelos alinhados ao domínio com risco controlado",
          "Ciclo de iteração mais rápido e seguro",
          "Entrega pronta para produção com rastreabilidade"
        ],
        "highlights": [
          "Curadoria de dados + LoRA/PEFT com rastreabilidade e ablação",
          "Avaliação rigorosa: qualidade, segurança e regressão antes do deploy",
          "Inferência: otimização de custo/latência (batching/cache/quantização quando aplicável)"
        ],
        "stack": [
          "Transformers",
          "LoRA/PEFT",
          "Hugging Face",
          "Eval",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Detalhes de datasets/modelos dependem do caso de uso.",
        "image": "assets/projects/project-generic.svg"
      },
      {
        "id": "eval",
        "title": "Avaliação & Observabilidade de LLMs",
        "subtitle": "Métricas, suites de teste e monitoramento para evitar regressões.",
        "problem": "LLMs degradam silenciosamente em produção; sem observabilidade, você só descobre quando o usuário reclama.",
        "approach": [
          "Golden set + testes automáticos por rota/caso (CI/CD) para detectar regressões cedo",
          "Métricas online: latência, custo, erro e qualidade percebida, com sampling e traces",
          "Tracing E2E: request -> retrieval -> prompt -> resposta (sem vazar PII)",
          "Guardrails: schema, políticas de dados e validações por contexto",
          "Processo de release: checklist + canary + rollback e playbooks de incidente"
        ],
        "impact": [
          "Detecção precoce e debug mais rápido",
          "Sistemas mais previsíveis e confiáveis",
          "Releases mais seguros (menos surpresas)"
        ],
        "highlights": [
          "Golden set + testes automáticos por rota/caso (CI/CD)",
          "Tracing E2E com custo/latência, sem vazamento de PII",
          "Alertas + playbooks para incidentes e regressões"
        ],
        "stack": [
          "LLMOps",
          "Observability",
          "Testing",
          "Python",
          "APIs"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Sem números inventados: métricas específicas variam por cliente e contexto.",
        "image": "assets/projects/project-lakehouse.svg"
      }
    ],
    "labels": {
      "repo": "Repo",
      "demo": "Demo",
      "writeup": "Writeup",
      "caseStudy": "Estudo de caso",
      "problem": "Problema",
      "approach": "Abordagem",
      "impact": "Impacto",
      "highlights": "Destaques",
      "stack": "Stack"
    },
    "experience": [
      {
        "when": "Open Source AI",
        "title": "Contribuições em OpenShift AI / InstructLab",
        "org": "Ecossistema Red Hat (conforme CV)",
        "bullets": [
          "Otimização e integração de modelos generativos em ambiente corporativo",
          "Práticas de engenharia: observabilidade, hardening e qualidade de entrega"
        ]
      },
      {
        "when": "NLP / Fine-tuning",
        "title": "Fine-tuning e pipelines (ecossistema Hugging Face)",
        "org": "Projetos e benchmarks de avaliação (conforme CV)",
        "bullets": [
          "Experimentos com LoRA/PEFT e avaliação de qualidade",
          "Pipelines de inferência com foco em desempenho e confiabilidade"
        ]
      },
      {
        "when": "Dados / Automação",
        "title": "Automação de fluxos corporativos + Lakehouse",
        "org": "Volk do Brasil (conforme CV)",
        "bullets": [
          "Automação com Python e integração de dados",
          "Aplicação de IA em plataforma Databricks (Delta/MLflow)"
        ]
      },
      {
        "when": "Embedded / Linux",
        "title": "Linux OEM e sistemas críticos",
        "org": "Perkons & Policorp (conforme CV)",
        "bullets": [
          "Customização de distribuições Linux OEM",
          "Engenharia embarcada e software mission-critical"
        ]
      }
    ],
    "education": [
      {
        "title": "Pós-graduação em Inteligência Artificial",
        "org": "UTFPR (Universidade Tecnológica Federal do Paraná)",
        "year": "2025",
        "note": "Curitiba, PR. Pós com viés aplicado e foco em engenharia para colocar IA em produção.",
        "bullets": [
          "Fundamentos de ML/IA com ênfase em validação e qualidade",
          "Pipelines end-to-end (dados → treino → deploy → monitoramento)",
          "Boas práticas de engenharia para sistemas com IA (testes, logs, observabilidade)"
        ]
      },
      {
        "title": "Pós-graduação em Engenharia de Software",
        "org": "Universidade Positivo",
        "year": "",
        "note": "Arquitetura, qualidade e manutenção sustentável de software.",
        "bullets": [
          "Arquitetura e padrões (design, modularidade, contratos)",
          "Testes automatizados e qualidade (regressão, cobertura, revisão)",
          "Documentação e práticas de entrega (versionamento, releases)"
        ]
      },
      {
        "title": "Tecnólogo em Análise e Desenvolvimento de Sistemas",
        "org": "Universidade Positivo",
        "year": "",
        "note": "Base sólida para engenharia de software: desenvolvimento, dados e sistemas.",
        "bullets": [
          "Desenvolvimento (fundamentos) e integração de sistemas",
          "Banco de dados e modelagem",
          "Sistemas operacionais e redes (fundamentos)"
        ]
      },
      {
        "title": "Pós-graduação em IA Generativa Aplicada",
        "org": "UTFPR (Universidade Tecnológica Federal do Paraná)",
        "year": "Início Abr/2026",
        "note": "Especialização aplicada em LLMs, RAG e agentes com foco em engenharia e operação.",
        "bullets": [
          "Arquiteturas de LLM systems (RAG, agentes, tool-calling)",
          "LLMOps: avaliação, guardrails e monitoramento",
          "Integração em sistemas empresariais (APIs, dados, segurança)"
        ]
      }
    ],
    "certifications": [
      {
        "title": "Hugging Face Agents Course",
        "issuer": "Hugging Face",
        "date": "Jun/2025",
        "badge": "assets/badges/huggingface.svg",
        "note": "Agents, tool calling e workflows multi-step"
      },
      {
        "title": "Microsoft Professional Program: Artificial Intelligence",
        "issuer": "Microsoft",
        "date": "",
        "badge": "assets/badges/microsoft.svg",
        "note": "Certificado de conclusão"
      },
      {
        "title": "Microsoft Certified: Azure AI Engineer Associate",
        "issuer": "Microsoft Azure",
        "date": "",
        "badge": "assets/badges/azure.svg",
        "note": "Azure AI Engineer"
      },
      {
        "title": "AWS Certified Machine Learning Engineer",
        "issuer": "AWS",
        "date": "",
        "badge": "assets/badges/aws.svg",
        "note": "Machine Learning"
      },
      {
        "title": "AWS Certified Generative AI Developer",
        "issuer": "AWS",
        "date": "",
        "badge": "assets/badges/aws.svg",
        "note": "Generative AI"
      }
    ],
    "quickLinks": [
      {
        "label": "LinkedIn",
        "href": "https://br.linkedin.com/in/johnny-nordio-533769251",
        "external": true
      },
      {
        "label": "GitHub",
        "href": "https://github.com/Nordio1",
        "external": true
      },
      {
        "label": "WhatsApp",
        "href": "https://wa.me/5541995879232",
        "external": true
      },
      {
        "label": "Email",
        "href": "mailto:mrnordio@icloud.com",
        "external": false
      }
    ],
    "contact": {
      "cardTitle": "Fale comigo",
      "cardSub": "Posso compartilhar writeups técnicos e detalhes dos estudos de caso.",
      "phoneCta": "WhatsApp",
      "linkedinCta": "LinkedIn",
      "quickTitle": "Links rápidos",
      "quickNote": "Links úteis para contato e portfólio.",
      "privacy": "Página pública. Sem scripts de tracking."
    },
    "footer": {
      "backTop": "Voltar ao topo"
    },
    "lab": {
      "legend": [
        {
          "label": "RAG",
          "hint": "Recuperação + geração"
        },
        {
          "label": "Agentes",
          "hint": "Tool-calling multi-step"
        },
        {
          "label": "Avaliação",
          "hint": "Qualidade e regressão"
        },
        {
          "label": "LLMOps",
          "hint": "Deploy e monitoramento"
        }
      ],
      "nodes": [
        {
          "id": "sources",
          "label": "Fontes",
          "x": 16,
          "y": 20,
          "title": "Fontes e ingestão",
          "body": "Ponto de partida: documentos, tabelas, eventos e dados operacionais. A chave é consistência e rastreabilidade.",
          "bullets": [
            "Normalização e deduplicação",
            "Controle de versões de dados",
            "Trilha de auditoria (o que entrou e quando)"
          ],
          "links": [
            "chunking"
          ]
        },
        {
          "id": "chunking",
          "label": "Chunking",
          "x": 38,
          "y": 30,
          "title": "Chunking e indexação",
          "body": "Separar conteúdo em partes recuperáveis aumenta a qualidade do RAG. Estratégias mudam por domínio.",
          "bullets": [
            "Chunking por estrutura (título/seção/tabela)",
            "Metadados para filtros",
            "Testes de recall/precision"
          ],
          "links": [
            "vectors",
            "eval"
          ]
        },
        {
          "id": "vectors",
          "label": "Vetores",
          "x": 60,
          "y": 18,
          "title": "Embeddings + vector store",
          "body": "Embeddings traduzem texto em vetores. O index precisa ser rápido, consistente e observável.",
          "bullets": [
            "FAISS/Chroma e filtros",
            "Cache e batching",
            "Reranking quando necessário"
          ],
          "links": [
            "rag"
          ]
        },
        {
          "id": "rag",
          "label": "RAG",
          "x": 72,
          "y": 42,
          "title": "RAG (retrieval + geração)",
          "body": "Resposta com base em evidências recuperadas. O objetivo é reduzir alucinação e aumentar precisão.",
          "bullets": [
            "Contexto citado/ancorado",
            "Prompts estruturados",
            "Fallbacks e limites"
          ],
          "links": [
            "guardrails",
            "eval"
          ]
        },
        {
          "id": "agents",
          "label": "Agentes",
          "x": 22,
          "y": 58,
          "title": "Agentes com ferramentas",
          "body": "Agentes chamam ferramentas/APIs. O segredo é previsibilidade: limites, validação e logs úteis.",
          "bullets": [
            "Tool-calling com validação",
            "Execução multi-step controlada",
            "Erros previsíveis e rastreáveis"
          ],
          "links": [
            "guardrails",
            "ops"
          ]
        },
        {
          "id": "guardrails",
          "label": "Guardrails",
          "x": 52,
          "y": 60,
          "title": "Guardrails e segurança",
          "body": "Regras para evitar saídas perigosas e reduzir comportamento inesperado em produção.",
          "bullets": [
            "Validação de entrada/saída",
            "Políticas de dados e PII",
            "Rate limits e timeouts"
          ],
          "links": [
            "eval"
          ]
        },
        {
          "id": "eval",
          "label": "Avaliação",
          "x": 78,
          "y": 70,
          "title": "Avaliação contínua",
          "body": "Sem avaliação, sistema degrada. O foco é criar testes e métricas que detectem regressão cedo.",
          "bullets": [
            "Suites offline (golden set)",
            "Métricas online (qualidade/latência)",
            "Observabilidade e alertas"
          ],
          "links": [
            "ops"
          ]
        },
        {
          "id": "ops",
          "label": "LLMOps",
          "x": 90,
          "y": 56,
          "title": "LLMOps (deploy e monitoramento)",
          "body": "Entrega com controle: versionamento, canary, rollback e monitoramento por custo/latência/qualidade.",
          "bullets": [
            "MLflow / tracking",
            "Deploy seguro (canary/rollback)",
            "Monitoramento + auditoria"
          ],
          "links": []
        }
      ]
    },
    "toolbox": {
      "clear": "Limpar",
      "help": "Dica: Shift+clique para selecionar mais de um item.",
      "countLabel": "projetos"
    },
    "cmdk": {
      "open": "Comandos",
      "title": "Comandos",
      "placeholder": "Buscar seções, projetos e links...",
      "hint": "Use â/â e Enter. Pressione Ctrl+K para abrir de qualquer lugar.",
      "sectionHint": "Ir para seção",
      "actionHint": "Ação rápida",
      "toggleTheme": "Alternar tema",
      "email": "E-mail",
      "whatsapp": "WhatsApp",
      "kinds": {
        "section": "Seção",
        "project": "Projeto",
        "link": "Link",
        "action": "Ação"
      }
    }
  },
  "en": {
    "meta": {
      "title": "Johnny Nordio | AI Engineer",
      "description": "Artificial Intelligence Engineer focused on Generative AI, LLMs, RAG, agents, and LLMOps.",
      "ogDescription": "Generative AI • LLMs • RAG • Agents • LLMOps"
    },
    "profile": {
      "email": "mrnordio@icloud.com",
      "whatsapp": "https://wa.me/5541995879232",
      "github": "https://github.com/Nordio1",
      "linkedin": "https://br.linkedin.com/in/johnny-nordio-533769251"
    },
    "nav": {
      "about": "Summary",
      "skills": "Skills",
      "projects": "Projects",
      "experience": "Experience",
      "education": "Education",
      "contact": "Contact",
      "lab": "Systems",
      "toolbox": "Toolbox"
    },
    "theme": {
      "toDark": "Dark mode",
      "toLight": "Light mode",
      "aria": "Toggle theme"
    },
    "hero": {
      "eyebrow": "AI ENGINEER",
      "name": "Johnny Nordio",
      "tagline": "AI ENGINEER | GENERATIVE AI SPECIALIST | LLM SYSTEMS ARCHITECT",
      "location": "Curitiba, Brazil | Open to Global Remote Roles",
      "ctaPrimary": "Email me",
      "ctaSecondary": "View projects",
      "ctaLinkedin": "LinkedIn",
      "note": "Some work is anonymized (NDA-friendly). Details available on request.",
      "panelTitle": "Focus",
      "panelTitle2": "What I build",
      "focus": [
        "LLMs",
        "RAG",
        "Agents",
        "LLMOps",
        "Fine-tuning (LoRA/PEFT)",
        "APIs & Integrations"
      ],
      "build": [
        "End-to-end RAG pipelines (ingestion → embeddings → vector store → generation)",
        "LLM evaluation, monitoring, and guardrails",
        "AI integration into enterprise ERPs and REST APIs",
        "Performance, stability, and observability improvements"
      ],
      "panelTitle3": "Pipelines",
      "pipelineHint": "Click to explore",
      "pipeline": [
        {
          "id": "ingest",
          "title": "Ingestion",
          "desc": "Docs, data, logs",
          "bullets": [
            "Ingestion with normalization + deduplication",
            "Chunking strategies per data type",
            "Source versioning and audit trail"
          ]
        },
        {
          "id": "embed",
          "title": "Embeddings",
          "desc": "Semantic representations",
          "bullets": [
            "Model selection by domain/cost/latency",
            "Batching and caching to reduce cost",
            "Continuous recall/precision evaluation"
          ]
        },
        {
          "id": "vector",
          "title": "Vector search",
          "desc": "Retrieval with relevance",
          "bullets": [
            "Vector DB (FAISS/Chroma) + filters",
            "Reranking when needed",
            "Query/hit observability"
          ]
        },
        {
          "id": "gen",
          "title": "Generation",
          "desc": "LLM with guardrails",
          "bullets": [
            "Structured prompting + context windows",
            "Output validation and guardrails",
            "Quality metrics (offline + online)"
          ]
        },
        {
          "id": "ops",
          "title": "LLMOps",
          "desc": "Deploy, monitoring, evaluation",
          "bullets": [
            "Experiment tracking (MLflow)",
            "Canary/rollback and security",
            "Drift monitoring and regressions"
          ]
        }
      ],
      "featureTitle": "Featured case studies",
      "featureSub": "Click to open a quick deep-dive (problem, approach, impact).",
      "featureHint": "Tip: Ctrl/Cmd+K to search sections, projects and links.",
      "featuredProjectIds": [
        "erp-crm",
        "rag",
        "agents"
      ]
    },
    "sections": {
      "aboutTitle": "Executive Summary",
      "aboutSub": "Pragmatic, production-focused, quality-driven.",
      "skillsTitle": "Strategic Expertise",
      "skillsSub": "Architecture, implementation, and delivery.",
      "projectsTitle": "Selected Projects",
      "projectsSub": "NDA-friendly case studies you can scan in 60 seconds.",
      "experienceTitle": "Experience & Contributions",
      "experienceSub": "What shipped, what improved, and what stabilized.",
      "educationTitle": "Education",
      "educationSub": "AI and software engineering with a hands-on bias.",
      "certsTitle": "Certifications",
      "certsSub": "Selected credentials and courses (GenAI, cloud, and engineering).",
      "contactTitle": "Contact",
      "contactSub": "Best: email. Fast: WhatsApp.",
      "labTitle": "Architectures in action",
      "labSub": "An interactive map of the building blocks I ship in production (RAG, agents, evaluation, LLMOps).",
      "toolboxTitle": "Toolbox",
      "toolboxSub": "Click a tag to highlight projects that actually use it."
    },
    "about": [
      "Artificial Intelligence Engineer focused on Generative AI, Large Language Models (LLMs), and Retrieval-Augmented Generation (RAG) architectures. Experienced in building end-to-end pipelines and integrating AI into enterprise systems (ERP, REST APIs, and Lakehouse platforms).",
      "Hands-on with fine-tuning (LoRA/PEFT), embeddings, vector databases, multi-step agents, and LLMOps. Strong engineering rigor: observability, testing, error handling, and a relentless focus on stability and latency.",
      "Some portfolio items are described as anonymized case studies (NDA-friendly). I can share deeper technical details on request."
    ],
    "skills": [
      {
        "group": "GenAI & LLMs",
        "items": [
          "RAG",
          "Multi-step agents",
          "Structured prompting",
          "Guardrails",
          "Evaluation & metrics"
        ]
      },
      {
        "group": "Fine-tuning & NLP",
        "items": [
          "LoRA/PEFT",
          "Hugging Face",
          "Tokenization",
          "Benchmarks",
          "Inference pipelines"
        ]
      },
      {
        "group": "Stacks & Tooling",
        "items": [
          "LangChain",
          "LlamaIndex",
          "FAISS",
          "Chroma",
          "Vector search"
        ]
      },
      {
        "group": "Lakehouse & MLOps",
        "items": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Model Serving",
          "Experiment tracking"
        ]
      },
      {
        "group": "Engineering",
        "items": [
          "Advanced Python",
          "REST APIs",
          "Testing",
          "Profiling",
          "Linux"
        ]
      },
      {
        "group": "Production Delivery",
        "items": [
          "Observability",
          "Hardening",
          "Rollbacks",
          "Versioning",
          "Docs"
        ]
      }
    ],
    "projects": [
      {
        "title": "Retail ERP/CRM (NDA) | Stability + Integrations",
        "subtitle": "Resilience, audit trail, and critical integrations in a desktop ERP/CRM (NDA).",
        "highlights": [
          "API hardening: validation, explicit errors, observability, and backwards-compatible contracts",
          "ERP<->CRM parity: route-level diagnostics, contracts, and consistent data roundtrip",
          "Guided critical flows (sales/payments) with end-to-end auditing"
        ],
        "stack": [
          "Python",
          "REST APIs",
          "Desktop app",
          "Databases",
          "Observability"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Anonymized case study (NDA-friendly). Deeper technical details on request.",
        "image": "assets/projects/project-erpcrm.svg",
        "id": "erp-crm",
        "problem": "Retail operations cannot tolerate instability: a disconnect during sales/stock/fiscal flows turns into rework, inconsistency, and expensive support.",
        "approach": [
          "Canonical API contracts + automated route checks to catch regressions before release",
          "Resilient networking (timeouts/backoff/fallback) with idempotent retries to avoid duplicate writes",
          "Consistent persistence: critical configs/state always in the database (no \"in-memory state\") + uniqueness validation",
          "Audit trail as source of truth: who did what/when, with operational messages and no secret leakage",
          "Profiling + query and lazy-load optimization to reduce first-click freezes on heavy screens"
        ],
        "impact": [
          "More predictable production behavior: fewer intermittent failures and safer reconnection",
          "Data integrity: ERP -> API -> CRM roundtrip without losing fields, with traceability",
          "Simpler operations: faster diagnosis and safer releases"
        ]
      },
      {
        "title": "Enterprise RAG System",
        "subtitle": "Full pipeline: ingestion → embeddings → vector store → generation.",
        "highlights": [
          "Versioned ingestion: dedup + metadata + structure-aware chunking",
          "Hybrid retrieval: filters + vectors + reranking, with cache + observability",
          "Production quality: evaluation suites + guardrails + evidence-backed answers"
        ],
        "stack": [
          "RAG",
          "Embeddings",
          "FAISS/Chroma",
          "LLMOps",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Data sources and documents vary by domain (fast adaptation per use case).",
        "image": "assets/projects/project-rag.svg",
        "id": "rag",
        "problem": "Naive RAG breaks in production: documents change, retrieval brings noise, and nobody measures quality, leading to confident-but-wrong answers.",
        "approach": [
          "Incremental ingestion pipeline with source versioning, deduplication, and metadata",
          "Adaptive chunking per doc type (headings/sections/tables) + normalization",
          "Retrieval with vectors + filters, reranking, and tuning by recall/precision",
          "Continuous evaluation (golden set) + regression gates before prompt/model changes",
          "Guardrails: schemas, PII redaction, required citations, and cost/latency controls"
        ],
        "impact": [
          "More trustworthy, auditable answers (evidence-backed)",
          "Lower hallucination risk and fewer silent regressions",
          "A measurable improvement loop: measure -> adjust -> re-validate"
        ]
      },
      {
        "title": "AI Agent Workflows",
        "subtitle": "Autonomous agents integrated with tools and external APIs, safely.",
        "highlights": [
          "Safe tool-calling: schemas, allowlists, budgets/timeouts, strict I/O validation",
          "Deterministic orchestration: explicit state, useful logs, and execution replay",
          "Scenario evaluation + regression: agents treated as real software"
        ],
        "stack": [
          "Agents",
          "Tooling",
          "Guardrails",
          "APIs",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Robustness first: controlled execution, useful logs, predictable failures.",
        "image": "assets/projects/project-agents.svg",
        "id": "agents",
        "problem": "Agents that call tools have real side effects; without limits they become unpredictable, unsafe, and hard to debug.",
        "approach": [
          "Tool design with contracts (schemas) and strict input/output validation",
          "Security policies: allowlists, budgets/timeouts, rate limits, and human approval for sensitive actions",
          "Multi-step orchestration with explicit state, idempotency, and step-level logs",
          "Scenario-based test harness + replay for debugging and regression",
          "Observability: step tracing, cost/latency, and actionable errors"
        ],
        "impact": [
          "Agents that behave like software: predictable, testable, operable",
          "Lower operational risk when integrating external systems",
          "Faster time-to-market for new workflows and tools"
        ]
      },
      {
        "title": "Lakehouse LLMOps (Databricks)",
        "subtitle": "Data integration + model traceability in enterprise environments.",
        "highlights": [
          "Lineage + reproducibility: Delta Lake + data quality checks",
          "Model governance: MLflow tracking/registry + canary/rollback",
          "Operational metrics + alerts (no invented numbers)"
        ],
        "stack": [
          "Databricks",
          "Delta Lake",
          "MLflow",
          "Serving",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Patterns ready for monitoring, versioning, and continuous delivery.",
        "image": "assets/projects/project-lakehouse.svg",
        "id": "lakehouse",
        "problem": "Without governance, the data/model lifecycle becomes a black box: hard to reproduce, audit, and operate under pressure.",
        "approach": [
          "Lakehouse pipelines with versioning, validation, and lineage",
          "MLflow tracking/registry/versioning with reproducible artifacts",
          "Canary + rollback deployment and monitoring by cost/latency/quality",
          "Integration with legacy systems/APIs and access controls",
          "Continuous ops: alerts, playbooks, and validation routines"
        ],
        "impact": [
          "End-to-end delivery that is controlled and auditable",
          "Faster response to incidents and regressions",
          "A foundation that scales across domains/teams"
        ]
      },
      {
        "id": "finetune",
        "title": "Transformer Fine-Tuning (LoRA/PEFT)",
        "subtitle": "Fine-tuning focused on quality, cost, and experiment governance.",
        "problem": "Base models rarely match a domain's language; fine-tuning without evaluation leads to overfitting and hard-to-notice regressions.",
        "approach": [
          "Dataset curation/cleaning/slicing and instruction design per objective",
          "LoRA/PEFT with reproducible experiments + versioned data/configs",
          "Benchmarks and qualitative+quantitative evaluation with baselines and ablations",
          "Inference pipelines with latency/cost awareness + monitoring",
          "Release gates and rollback when quality degrades"
        ],
        "impact": [
          "Domain-aligned models with controlled risk",
          "Faster, safer iteration cycles",
          "Production-ready delivery with traceability"
        ],
        "highlights": [
          "Data curation + LoRA/PEFT with traceability and ablations",
          "Rigorous evaluation: quality, safety, and regression before deployment",
          "Inference: cost/latency optimization (batching/cache/quantization when applicable)"
        ],
        "stack": [
          "Transformers",
          "LoRA/PEFT",
          "Hugging Face",
          "Eval",
          "Python"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "Model/dataset details vary by use case.",
        "image": "assets/projects/project-generic.svg"
      },
      {
        "id": "eval",
        "title": "LLM Evaluation & Observability",
        "subtitle": "Metrics, test suites, and monitoring to prevent regressions.",
        "problem": "LLMs degrade silently in production; without observability you only learn when users complain.",
        "approach": [
          "Golden set + route/scenario tests in CI/CD to catch regressions early",
          "Online metrics: latency, cost, errors, and perceived quality with sampling and traces",
          "E2E tracing: request -> retrieval -> prompt -> output (no PII leakage)",
          "Guardrails: schemas, data policies, and context-aware validation",
          "Release process: checklist + canary + rollback and incident playbooks"
        ],
        "impact": [
          "Earlier detection and faster debugging",
          "More predictable, reliable systems",
          "Safer releases with fewer surprises"
        ],
        "highlights": [
          "Golden sets + automated tests per route/scenario (CI/CD)",
          "E2E tracing with cost/latency, without PII leakage",
          "Alerts + playbooks for incidents and regressions"
        ],
        "stack": [
          "LLMOps",
          "Observability",
          "Testing",
          "Python",
          "APIs"
        ],
        "links": {
          "repo": "",
          "demo": "",
          "writeup": ""
        },
        "disclaimer": "No fabricated numbers: metrics are context-dependent.",
        "image": "assets/projects/project-lakehouse.svg"
      }
    ],
    "labels": {
      "repo": "Repo",
      "demo": "Demo",
      "writeup": "Writeup",
      "caseStudy": "Case study",
      "problem": "Problem",
      "approach": "Approach",
      "impact": "Impact",
      "highlights": "Highlights",
      "stack": "Stack"
    },
    "experience": [
      {
        "when": "Open Source AI",
        "title": "OpenShift AI / InstructLab contributions",
        "org": "Red Hat ecosystem (per CV)",
        "bullets": [
          "Contributions and improvements focused on GenAI workflows for enterprise use",
          "Hardening: error handling, useful logs, validations, predictable behavior",
          "Performance/latency improvements and fewer intermittent pipeline failures",
          "Engineering discipline: tests, release notes, sustainable maintenance"
        ]
      },
      {
        "when": "NLP / Fine-tuning",
        "title": "Fine-tuning and inference pipelines (Hugging Face ecosystem)",
        "org": "Projects and evaluation benchmarks (per CV)",
        "bullets": [
          "LoRA/PEFT experiments and quality evaluation",
          "Inference pipelines with performance and reliability focus"
        ]
      },
      {
        "when": "Data / Automation",
        "title": "Enterprise workflow automation + Lakehouse",
        "org": "Volk do Brasil (per CV)",
        "bullets": [
          "Python automation and data integration across systems",
          "Lakehouse pipelines (Delta) with traceability and data quality",
          "MLflow for experiment tracking/versioning and governance",
          "Integration with enterprise APIs and legacy systems"
        ]
      },
      {
        "when": "Embedded / Linux",
        "title": "Linux OEM and mission-critical systems",
        "org": "Perkons & Policorp (per CV)",
        "bullets": [
          "Linux OEM distribution customization and build/deploy processes",
          "Embedded engineering and hardware integrations when applicable",
          "Stability focus: diagnosis, logs, safe fixes",
          "Tooling and processes for critical software maintenance"
        ]
      }
    ],
    "education": [
      {
        "title": "Postgraduate Degree in Artificial Intelligence",
        "org": "UTFPR (Federal University of Technology – Paraná)",
        "year": "2025",
        "note": "Curitiba, Brazil. Applied AI program with an engineering bias toward production.",
        "bullets": [
          "ML/AI fundamentals with emphasis on validation and quality",
          "End-to-end pipelines (data → training → deploy → monitoring)",
          "Engineering practices for AI systems (tests, logs, observability)"
        ]
      },
      {
        "title": "Postgraduate Degree in Software Engineering",
        "org": "Universidade Positivo",
        "year": "",
        "note": "Software architecture, quality, and sustainable maintenance.",
        "bullets": [
          "Architecture and patterns (modularity, contracts, maintainability)",
          "Automated testing and quality (regression, coverage, reviews)",
          "Delivery practices (versioning, releases, documentation)"
        ]
      },
      {
        "title": "Technologist Degree in Systems Analysis and Development",
        "org": "Universidade Positivo",
        "year": "",
        "note": "Solid foundation for software engineering: development, data, and systems.",
        "bullets": [
          "Development fundamentals and system integration",
          "Databases and data modeling",
          "Operating systems and networking fundamentals"
        ]
      },
      {
        "title": "Postgraduate Degree in Applied Generative AI",
        "org": "UTFPR (Federal University of Technology – Paraná)",
        "year": "Starting Apr/2026",
        "note": "Applied specialization in LLMs, RAG and agents with a focus on engineering and operations.",
        "bullets": [
          "LLM system architectures (RAG, agents, tool-calling)",
          "LLMOps: evaluation, guardrails, monitoring",
          "Enterprise integration (APIs, data, security)"
        ]
      }
    ],
    "certifications": [
      {
        "title": "Hugging Face Agents Course",
        "issuer": "Hugging Face",
        "date": "Jun 2025",
        "badge": "assets/badges/huggingface.svg",
        "note": "Agents, tool calling, and multi-step workflows"
      },
      {
        "title": "Microsoft Professional Program: Artificial Intelligence",
        "issuer": "Microsoft",
        "date": "",
        "badge": "assets/badges/microsoft.svg",
        "note": "Completion certificate"
      },
      {
        "title": "Microsoft Certified: Azure AI Engineer Associate",
        "issuer": "Microsoft Azure",
        "date": "",
        "badge": "assets/badges/azure.svg",
        "note": "Azure AI Engineer"
      },
      {
        "title": "AWS Certified Machine Learning Engineer",
        "issuer": "AWS",
        "date": "",
        "badge": "assets/badges/aws.svg",
        "note": "Machine Learning"
      },
      {
        "title": "AWS Certified Generative AI Developer",
        "issuer": "AWS",
        "date": "",
        "badge": "assets/badges/aws.svg",
        "note": "Generative AI"
      }
    ],
    "quickLinks": [
      {
        "label": "LinkedIn",
        "href": "https://br.linkedin.com/in/johnny-nordio-533769251",
        "external": true
      },
      {
        "label": "GitHub",
        "href": "https://github.com/Nordio1",
        "external": true
      },
      {
        "label": "WhatsApp",
        "href": "https://wa.me/5541995879232",
        "external": true
      },
      {
        "label": "Email",
        "href": "mailto:mrnordio@icloud.com",
        "external": false
      }
    ],
    "contact": {
      "cardTitle": "Get in touch",
      "cardSub": "Happy to share deeper technical writeups and case study details.",
      "phoneCta": "WhatsApp",
      "linkedinCta": "LinkedIn",
      "quickTitle": "Quick links",
      "quickNote": "Useful links for contact and work.",
      "privacy": "Public page. No tracking scripts."
    },
    "footer": {
      "backTop": "Back to top"
    },
    "lab": {
      "legend": [
        {
          "label": "RAG",
          "hint": "Retrieval + generation"
        },
        {
          "label": "Agents",
          "hint": "Multi-step tool calling"
        },
        {
          "label": "Evaluation",
          "hint": "Quality and regressions"
        },
        {
          "label": "LLMOps",
          "hint": "Deploy and monitoring"
        }
      ],
      "nodes": [
        {
          "id": "sources",
          "label": "Sources",
          "x": 16,
          "y": 20,
          "title": "Sources and ingestion",
          "body": "Starting point: documents, tables, events, operational data. The key is consistency and traceability.",
          "bullets": [
            "Normalization and deduplication",
            "Data versioning",
            "Audit trail (what/when)"
          ],
          "links": [
            "chunking"
          ]
        },
        {
          "id": "chunking",
          "label": "Chunking",
          "x": 38,
          "y": 30,
          "title": "Chunking and indexing",
          "body": "Splitting content into retrievable units improves RAG quality. Strategies vary by domain.",
          "bullets": [
            "Structure-aware chunking",
            "Metadata for filters",
            "Recall/precision testing"
          ],
          "links": [
            "vectors",
            "eval"
          ]
        },
        {
          "id": "vectors",
          "label": "Vectors",
          "x": 60,
          "y": 18,
          "title": "Embeddings + vector store",
          "body": "Embeddings turn text into vectors. Indexes must be fast, consistent, and observable.",
          "bullets": [
            "FAISS/Chroma and filters",
            "Caching and batching",
            "Reranking when needed"
          ],
          "links": [
            "rag"
          ]
        },
        {
          "id": "rag",
          "label": "RAG",
          "x": 72,
          "y": 42,
          "title": "RAG (retrieval + generation)",
          "body": "Evidence-grounded answers. Goal: reduce hallucination and increase accuracy.",
          "bullets": [
            "Anchored context",
            "Structured prompts",
            "Fallbacks and limits"
          ],
          "links": [
            "guardrails",
            "eval"
          ]
        },
        {
          "id": "agents",
          "label": "Agents",
          "x": 22,
          "y": 58,
          "title": "Tool-enabled agents",
          "body": "Agents call tools/APIs. The secret is predictability: limits, validation, and useful logs.",
          "bullets": [
            "Tool calling with validation",
            "Controlled multi-step execution",
            "Predictable failures"
          ],
          "links": [
            "guardrails",
            "ops"
          ]
        },
        {
          "id": "guardrails",
          "label": "Guardrails",
          "x": 52,
          "y": 60,
          "title": "Guardrails and safety",
          "body": "Policies to reduce unsafe outputs and unexpected behavior in production.",
          "bullets": [
            "I/O validation",
            "Data/PII policies",
            "Rate limits and timeouts"
          ],
          "links": [
            "eval"
          ]
        },
        {
          "id": "eval",
          "label": "Evaluation",
          "x": 78,
          "y": 70,
          "title": "Continuous evaluation",
          "body": "Without evaluation, systems degrade. Focus: tests and metrics that catch regressions early.",
          "bullets": [
            "Offline suites (golden set)",
            "Online metrics (quality/latency)",
            "Observability and alerts"
          ],
          "links": [
            "ops"
          ]
        },
        {
          "id": "ops",
          "label": "LLMOps",
          "x": 90,
          "y": 56,
          "title": "LLMOps (deploy and monitoring)",
          "body": "Delivery with control: versioning, canary, rollback and monitoring for cost/latency/quality.",
          "bullets": [
            "MLflow / tracking",
            "Safe deploy (canary/rollback)",
            "Monitoring + audit trail"
          ],
          "links": []
        }
      ]
    },
    "toolbox": {
      "clear": "Clear",
      "help": "Tip: Shift+click to multi-select.",
      "countLabel": "projects"
    },
    "cmdk": {
      "open": "Cmd+K",
      "title": "Command palette",
      "placeholder": "Search sections, projects and links...",
      "hint": "Use ↑/↓ and Enter. Press Ctrl+K (or Cmd+K) from anywhere.",
      "sectionHint": "Jump to section",
      "actionHint": "Quick action",
      "toggleTheme": "Toggle theme",
      "email": "Email",
      "whatsapp": "WhatsApp",
      "kinds": {
        "section": "Section",
        "project": "Project",
        "link": "Link",
        "action": "Action"
      }
    }
  }
}
